{
  "hash": "4eb5c5946e13bd394cd6269af6c10ec2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"SVMs and more tuning\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse) # All the mlr3 things\nlibrary(ggplot2) # For plotting\n\n# Spam Task setup\nspam_task <- tsk(\"spam\")\nset.seed(26)\n\n# train/test split\nspam_split <- partition(spam_task, ratio = 2 / 3)\n```\n:::\n\n\nGoals of this part:\n\n1.  Introduce SVMs\n2.  Tune an SVM with a more complex setup\n\n# Support Vector Machines\n\nLet's circle back to new learners and explore SVMs a little by trying out different kernels at the example of our penguin dataset we used in the beginning:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins <- na.omit(palmerpenguins::penguins)\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() +\n  labs(\n    title = \"Palmer Penguins\",\n    x = \"Flipper Length [mm]\",\n    y = \"Body Mass [g]\",\n    color = \"Species\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/penguins-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nSince we don't care about prediction accuracy for now, we'll use the whole dataset for training and prediction. Please only do this with toy data ðŸ™ƒ.\n\nFor the SVM algorithm itself, we use the `svm` learner from the `{e1071}` package (great name, I know) but once again use `{mlr3}`'s interface\n\nAccording to the docs (`?e1071::svm`) we have the choice of the following kernels:\n\n-   `\"linear\"`: $u'v$\n-   `\"polynomial\"`: $(\\mathtt{gamma} \\cdot u' \\cdot v + \\mathtt{coef0})^\\mathtt{degree}$\n-   `\"radial\"`: $\\exp(-\\mathtt{gamma} \\cdot |u-v|^2)$\n-   `\"sigmoid\"`: $\\tanh(\\mathtt{gamma} \\cdot u'v + \\mathtt{coef0})$\n\nWhere `gamma`, `degree`, and `coef0` are further hyperparameters.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsvm_learner <- lrn(\"classif.svm\")\n\n# What parameters do we have and what's the default kernel?\nsvm_learner$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> <ParamSet(16)>\n#> Key: <id>\n#>                  id    class lower upper nlevels          default parents\n#>              <char>   <char> <num> <num>   <num>           <list>  <list>\n#>  1:       cachesize ParamDbl  -Inf   Inf     Inf               40  [NULL]\n#>  2:   class.weights ParamUty    NA    NA     Inf           [NULL]  [NULL]\n#>  3:           coef0 ParamDbl  -Inf   Inf     Inf                0  kernel\n#>  4:            cost ParamDbl     0   Inf     Inf                1    type\n#>  5:           cross ParamInt     0   Inf     Inf                0  [NULL]\n#>  6: decision.values ParamLgl    NA    NA       2            FALSE  [NULL]\n#>  7:          degree ParamInt     1   Inf     Inf                3  kernel\n#>  8:         epsilon ParamDbl     0   Inf     Inf              0.1  [NULL]\n#>  9:          fitted ParamLgl    NA    NA       2             TRUE  [NULL]\n#> 10:           gamma ParamDbl     0   Inf     Inf   <NoDefault[0]>  kernel\n#> 11:          kernel ParamFct    NA    NA       4           radial  [NULL]\n#> 12:              nu ParamDbl  -Inf   Inf     Inf              0.5    type\n#> 13:           scale ParamUty    NA    NA     Inf             TRUE  [NULL]\n#> 14:       shrinking ParamLgl    NA    NA       2             TRUE  [NULL]\n#> 15:       tolerance ParamDbl     0   Inf     Inf            0.001  [NULL]\n#> 16:            type ParamFct    NA    NA       2 C-classification  [NULL]\n#>      value\n#>     <list>\n#>  1: [NULL]\n#>  2: [NULL]\n#>  3: [NULL]\n#>  4: [NULL]\n#>  5: [NULL]\n#>  6: [NULL]\n#>  7: [NULL]\n#>  8: [NULL]\n#>  9: [NULL]\n#> 10: [NULL]\n#> 11: [NULL]\n#> 12: [NULL]\n#> 13: [NULL]\n#> 14: [NULL]\n#> 15: [NULL]\n#> 16: [NULL]\n```\n\n\n:::\n:::\n\n\n## Your Turn!\n\nBelow you have a boilerplate for\n\na)  Creating an SVM learner and train it on the penguin dataset with 2 predictors\nb)  Plotting decision boundaries with it (using the `{mlr3}` helper function)\n\nRun the code below once to see what linear decision boundaries look like, then pick different kernels from the list above and run it again.\n\n-   What kernel would you pick just by the looks of the boundaries?\n-   How do the boundaries change if you also adjust the other hyperparameters?\n-   Try picking any other two variables as features (`penguin_task$col_info`)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguin_task <- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\npenguin_task$col_roles$feature <- c(\"body_mass_g\", \"flipper_length_mm\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create the learner, picking a kernel and/or other hyperparams\nsvm_learner <- lrn(\"classif.svm\", kernel = \"polynomial\", degree = 3)\n\n# Plot decision boundaries\nplot_learner_prediction(\n  learner = svm_learner,\n  task = penguin_task\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> INFO  [02:33:48.710] [mlr3] Applying learner 'classif.svm' on task 'na.omit(palmerpenguins::penguins)' (iter 1/1)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/svm-decision-boundaries-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# your code\n```\n:::\n\n\n::: {.callout-tip title=\"Example solution\" collapse =\"true\"}\n\nDirectly comparing multiple kernels with default parameters:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguin_task <- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\npenguin_task$col_roles$feature <- c(\"body_mass_g\", \"flipper_length_mm\")\n\n# Create a list of plots for each kernel\nplots <- lapply(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\"), \\(kernel) {\n  plot_learner_prediction(\n    learner = lrn(\"classif.svm\", kernel = kernel),\n    task = penguin_task\n  ) +\n    labs(subtitle = paste(\"SVM with \", kernel, \"kernel\"))\n})\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> INFO  [02:33:49.116] [mlr3] Applying learner 'classif.svm' on task 'na.omit(palmerpenguins::penguins)' (iter 1/1)\n#> INFO  [02:33:49.196] [mlr3] Applying learner 'classif.svm' on task 'na.omit(palmerpenguins::penguins)' (iter 1/1)\n#> INFO  [02:33:49.281] [mlr3] Applying learner 'classif.svm' on task 'na.omit(palmerpenguins::penguins)' (iter 1/1)\n#> INFO  [02:33:49.368] [mlr3] Applying learner 'classif.svm' on task 'na.omit(palmerpenguins::penguins)' (iter 1/1)\n```\n\n\n:::\n\n```{.r .cell-code}\n# Arrange the plots with the patchwork package\npatchwork::wrap_plots(plots, guides = \"collect\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n#> Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n#> Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n#> Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/svm-kernel-boundaries-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n\n## SVM-Tuning\n\nLet's try a more complex tuning experiment, based on the spam task from before.\n\nWe'll create a new SVM learner object and this time explicitly tell it which classification to do --- that's the default value anyway, but `{mlr3}` wants us to be explicit here for tuning:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsvm_learner <- lrn(\n  \"classif.svm\",\n  predict_type = \"prob\",\n  type = \"C-classification\"\n)\n```\n:::\n\n\nFirst up we'll define our search space, meaning the range of parameters we want to test out. Since `kernel` is a categorical parameter (i.e. no numbers, just names of kernels), we'll define the search space for that parameter by just passing the names of the kernels to the `p_fct()` helper function that defines `factor`-parameters in `{mlr3}`.\n\nThe interesting thing here is that some parameters are only relevant for some kernels, which we can declare via a `depends` argument:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsearch_space_svm = ps(\n  kernel = p_fct(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\")),\n  # Degree is onoly relevant if \"kernel\" is \"polynomial\"\n  degree = p_int(lower = 1, upper = 7, depends = kernel == \"polynomial\")\n)\n```\n:::\n\n\nWe can create an example design grid to inspect our setup and see that `degree` is `NA` for cases where `kernel` is not `\"polynomial\"`, just as we expected\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngenerate_design_grid(search_space_svm, resolution = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> <Design> with 6 rows:\n#>        kernel degree\n#>        <char>  <int>\n#> 1:     linear     NA\n#> 2: polynomial      1\n#> 3: polynomial      4\n#> 4: polynomial      7\n#> 5:     radial     NA\n#> 6:    sigmoid     NA\n```\n\n\n:::\n:::\n\n\n## Your Turn!\n\nThe above should get you started to...\n\n1.  Create a `search_space_svm` like above, tuning...\n\n-   `cost` from 0.1 to 1 (hint: `trafo = function(x) 10^x`)\n-   `kernel`, (like above example)\n-   `degree`, as above, **only if** `kernel == \"polynomial\"`\n-   `gamma`, from e.g. 0.01 to 0.2, **only if** `kernel` is polynomial, radial, sigmoid (hint: you can't use `kernel != \"linear\"` unfortunately, but `kernel %in% c(...)`) works\n\n2.  Use the `auto_tuner` function as previously seen with\n\n-   `svm_learner` (see above)\n-   A resampling strategy (use `\"holdout\"` if runtime is an issue)\n-   A measure (e.g. `classif.acc` or `classif.auc`)\n-   The search space you created in 1.\n-   A termination criterion (e.g. 40 evaluations)\n-   Random search as your tuning strategy\n\n3.  Train the auto-tuned learner and evaluate on the test set\n\nWhat parameter settings worked best?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# your code\n```\n:::\n\n\n::: {.callout-tip title=\"Example solution\" collapse =\"true\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsearch_space_svm = ps(\n  cost = p_dbl(-1, 1, trafo = function(x) 10^x),\n  kernel = p_fct(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\")),\n  degree = p_int(1, 7, depends = kernel == \"polynomial\"),\n  gamma = p_dbl(\n    lower = 0.01,\n    upper = 0.2,\n    depends = kernel %in% c(\"polynomial\", \"radial\", \"sigmoid\")\n  )\n)\n\ngrid <- generate_design_grid(search_space_svm, resolution = 6)\n\n# Look at grid with transformed cost param (manual way, there's probably a better one)\ngrid$data$cost_trafo <- 10^grid$data$cost\ngrid$data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       cost     kernel degree gamma cost_trafo\n#>      <num>     <char>  <int> <num>      <num>\n#>   1:    -1     linear     NA    NA        0.1\n#>   2:    -1 polynomial      1 0.010        0.1\n#>   3:    -1 polynomial      1 0.048        0.1\n#>   4:    -1 polynomial      1 0.086        0.1\n#>   5:    -1 polynomial      1 0.124        0.1\n#>  ---                                         \n#> 290:     1    sigmoid     NA 0.048       10.0\n#> 291:     1    sigmoid     NA 0.086       10.0\n#> 292:     1    sigmoid     NA 0.124       10.0\n#> 293:     1    sigmoid     NA 0.162       10.0\n#> 294:     1    sigmoid     NA 0.200       10.0\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(313)\n\ntuned_svm = auto_tuner(\n  learner = lrn(\n    \"classif.svm\",\n    predict_type = \"prob\",\n    type = \"C-classification\"\n  ),\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.auc\"),\n  search_space = search_space_svm,\n  terminator = trm(\"evals\", n_evals = 40),\n  tuner = tnr(\"random_search\")\n)\n\n# Tune!\ntuned_svm$train(spam_task, row_ids = spam_split$train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> INFO  [02:33:50.078] [bbotk] Starting to optimize 4 parameter(s) with '<OptimizerBatchRandomSearch>' and '<TerminatorEvals> [n_evals=40, k=0]'\n#> INFO  [02:33:50.108] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:50.115] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:50.120] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:50.676] [mlr3] Finished benchmark\n#> INFO  [02:33:50.814] [bbotk] Result of batch 1:\n#> INFO  [02:33:50.816] [bbotk]        cost  kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:33:50.816] [bbotk]  -0.6822099 sigmoid     NA 0.1616588   0.8734847        0      0\n#> INFO  [02:33:50.816] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:50.816] [bbotk]             0.551 2a706faa-52a7-4aa1-9f44-96d20b1c441e\n#> INFO  [02:33:50.824] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:50.831] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:50.836] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:51.326] [mlr3] Finished benchmark\n#> INFO  [02:33:51.341] [bbotk] Result of batch 2:\n#> INFO  [02:33:51.342] [bbotk]        cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:33:51.342] [bbotk]  -0.6450028 linear     NA    NA   0.9686214        0      0            0.486\n#> INFO  [02:33:51.342] [bbotk]                                 uhash\n#> INFO  [02:33:51.342] [bbotk]  ce65c812-7a5c-4e05-905a-db5c1e4675ad\n#> INFO  [02:33:51.351] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:51.357] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:51.361] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:51.784] [mlr3] Finished benchmark\n#> INFO  [02:33:51.799] [bbotk] Result of batch 3:\n#> INFO  [02:33:51.800] [bbotk]       cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:33:51.800] [bbotk]  0.8984124 sigmoid     NA 0.01141063   0.9285249        0      0\n#> INFO  [02:33:51.800] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:51.800] [bbotk]             0.418 55188f7b-d82c-4cf0-85ae-c40669ee55e8\n#> INFO  [02:33:51.809] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:51.815] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:51.819] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:52.342] [mlr3] Finished benchmark\n#> INFO  [02:33:52.357] [bbotk] Result of batch 4:\n#> INFO  [02:33:52.358] [bbotk]       cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:33:52.358] [bbotk]  0.1509409 sigmoid     NA 0.05019996    0.891037        0      0\n#> INFO  [02:33:52.358] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:52.358] [bbotk]             0.518 62f59832-fc88-4ab6-9975-16ee5d480567\n#> INFO  [02:33:52.367] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:52.373] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:52.378] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:52.869] [mlr3] Finished benchmark\n#> INFO  [02:33:52.890] [bbotk] Result of batch 5:\n#> INFO  [02:33:52.892] [bbotk]       cost  kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:33:52.892] [bbotk]  0.9455257 sigmoid     NA 0.1810499   0.8449879        0      0\n#> INFO  [02:33:52.892] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:52.892] [bbotk]             0.485 1c5cf5e0-bc2f-4d3b-9f8c-e385dc881ac5\n#> INFO  [02:33:52.902] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:52.908] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:52.914] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:53.477] [mlr3] Finished benchmark\n#> INFO  [02:33:53.492] [bbotk] Result of batch 6:\n#> INFO  [02:33:53.494] [bbotk]       cost     kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:33:53.494] [bbotk]  0.6023674 polynomial      3 0.09276489   0.9476628        0      0\n#> INFO  [02:33:53.494] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:53.494] [bbotk]             0.558 70e40131-e712-4e8e-a52e-ada2ffb97e5b\n#> INFO  [02:33:53.502] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:53.508] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:53.513] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:54.865] [mlr3] Finished benchmark\n#> INFO  [02:33:54.882] [bbotk] Result of batch 7:\n#> INFO  [02:33:54.884] [bbotk]       cost kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:33:54.884] [bbotk]  0.5193901 radial     NA 0.09999874   0.9607295        0      0\n#> INFO  [02:33:54.884] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:54.884] [bbotk]             1.348 05020e38-bbbb-4cc1-9d04-e5b5f2141878\n#> INFO  [02:33:54.893] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:54.899] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:54.904] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:56.359] [mlr3] Finished benchmark\n#> INFO  [02:33:56.374] [bbotk] Result of batch 8:\n#> INFO  [02:33:56.375] [bbotk]      cost kernel degree   gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:33:56.375] [bbotk]  0.390257 radial     NA 0.13199   0.9583802        0      0            1.446\n#> INFO  [02:33:56.375] [bbotk]                                 uhash\n#> INFO  [02:33:56.375] [bbotk]  267941ef-fb97-4887-a1ab-c1f048aefe36\n#> INFO  [02:33:56.385] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:56.391] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:56.397] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:56.908] [mlr3] Finished benchmark\n#> INFO  [02:33:56.925] [bbotk] Result of batch 9:\n#> INFO  [02:33:56.927] [bbotk]        cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:33:56.927] [bbotk]  -0.7548642 linear     NA    NA   0.9683802        0      0            0.507\n#> INFO  [02:33:56.927] [bbotk]                                 uhash\n#> INFO  [02:33:56.927] [bbotk]  782401c1-cd16-468a-a875-121b0d5e555f\n#> INFO  [02:33:56.936] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:56.942] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:56.950] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:58.244] [mlr3] Finished benchmark\n#> INFO  [02:33:58.261] [bbotk] Result of batch 10:\n#> INFO  [02:33:58.262] [bbotk]        cost kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:33:58.262] [bbotk]  -0.8124776 radial     NA 0.05523449   0.9514108        0      0\n#> INFO  [02:33:58.262] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:33:58.262] [bbotk]             1.289 acd9f349-2f0c-453c-910e-d77259cf942d\n#> INFO  [02:33:58.271] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:58.277] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:58.282] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:33:59.751] [mlr3] Finished benchmark\n#> INFO  [02:33:59.772] [bbotk] Result of batch 11:\n#> INFO  [02:33:59.773] [bbotk]       cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:33:59.773] [bbotk]  0.6799399 linear     NA    NA   0.9684968        0      0            1.464\n#> INFO  [02:33:59.773] [bbotk]                                 uhash\n#> INFO  [02:33:59.773] [bbotk]  f75f5805-e8af-4002-afe4-07a01a990f00\n#> INFO  [02:33:59.781] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:33:59.787] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:33:59.793] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:00.317] [mlr3] Finished benchmark\n#> INFO  [02:34:00.335] [bbotk] Result of batch 12:\n#> INFO  [02:34:00.337] [bbotk]       cost  kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:00.337] [bbotk]  0.7868932 sigmoid     NA 0.1636982   0.8478577        0      0\n#> INFO  [02:34:00.337] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:00.337] [bbotk]              0.52 f21fe9f3-6dbb-446d-a549-edd7d2146dc2\n#> INFO  [02:34:00.348] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:00.356] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:00.361] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:01.152] [mlr3] Finished benchmark\n#> INFO  [02:34:01.167] [bbotk] Result of batch 13:\n#> INFO  [02:34:01.169] [bbotk]        cost  kernel degree    gamma classif.auc warnings errors\n#> INFO  [02:34:01.169] [bbotk]  -0.9922801 sigmoid     NA 0.104775   0.9275121        0      0\n#> INFO  [02:34:01.169] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:01.169] [bbotk]             0.786 1db9f9f4-8b18-4d23-87c1-fc967273a7dc\n#> INFO  [02:34:01.178] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:01.185] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:01.190] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:01.669] [mlr3] Finished benchmark\n#> INFO  [02:34:01.685] [bbotk] Result of batch 14:\n#> INFO  [02:34:01.687] [bbotk]      cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:34:01.687] [bbotk]  0.790148 sigmoid     NA 0.06053824   0.8899437        0      0\n#> INFO  [02:34:01.687] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:01.687] [bbotk]             0.474 75beb619-feb5-4bae-b193-05d69f0304c3\n#> INFO  [02:34:01.696] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:01.702] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:01.707] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:02.893] [mlr3] Finished benchmark\n#> INFO  [02:34:02.909] [bbotk] Result of batch 15:\n#> INFO  [02:34:02.911] [bbotk]        cost kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:02.911] [bbotk]  -0.1012446 radial     NA 0.1207929   0.9579502        0      0\n#> INFO  [02:34:02.911] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:02.911] [bbotk]             1.181 ddf8b41b-aeed-43c8-b60d-13c978dcd1ff\n#> INFO  [02:34:02.921] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:02.927] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:02.932] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:03.522] [mlr3] Finished benchmark\n#> INFO  [02:34:03.538] [bbotk] Result of batch 16:\n#> INFO  [02:34:03.539] [bbotk]        cost     kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:03.539] [bbotk]  -0.2715305 polynomial      3 0.1355686   0.9532898        0      0\n#> INFO  [02:34:03.539] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:03.539] [bbotk]             0.583 8a6b26a4-35d8-437f-974e-cc3283f8a16b\n#> INFO  [02:34:03.550] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:03.556] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:03.562] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:04.920] [mlr3] Finished benchmark\n#> INFO  [02:34:04.935] [bbotk] Result of batch 17:\n#> INFO  [02:34:04.936] [bbotk]        cost kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:04.936] [bbotk]  -0.2421622 radial     NA 0.1686133    0.953742        0      0\n#> INFO  [02:34:04.936] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:04.936] [bbotk]             1.353 8a67a004-2f26-4a87-964c-3435097d6cf0\n#> INFO  [02:34:04.945] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:04.952] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:04.957] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:06.323] [mlr3] Finished benchmark\n#> INFO  [02:34:06.340] [bbotk] Result of batch 18:\n#> INFO  [02:34:06.341] [bbotk]        cost kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:34:06.341] [bbotk]  -0.9009985 radial     NA 0.09712621   0.9430044        0      0\n#> INFO  [02:34:06.341] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:06.341] [bbotk]              1.36 05293022-d283-4a47-86ae-0f5a9007288a\n#> INFO  [02:34:06.350] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:06.357] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:06.362] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:07.170] [mlr3] Finished benchmark\n#> INFO  [02:34:07.185] [bbotk] Result of batch 19:\n#> INFO  [02:34:07.186] [bbotk]       cost     kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:07.186] [bbotk]  0.3821866 polynomial      5 0.1204278   0.9233159        0      0\n#> INFO  [02:34:07.186] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:07.186] [bbotk]             0.804 46436fde-5969-4547-b1f1-05f597f9274e\n#> INFO  [02:34:07.195] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:07.201] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:07.206] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:07.931] [mlr3] Finished benchmark\n#> INFO  [02:34:07.947] [bbotk] Result of batch 20:\n#> INFO  [02:34:07.948] [bbotk]       cost     kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:07.948] [bbotk]  0.7460784 polynomial      7 0.1637225   0.9048633        0      0\n#> INFO  [02:34:07.948] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:07.948] [bbotk]              0.72 f1eb3ee0-5d46-4077-821e-948a25c5ed5e\n#> INFO  [02:34:07.961] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:07.967] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:07.973] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:09.406] [mlr3] Finished benchmark\n#> INFO  [02:34:09.425] [bbotk] Result of batch 21:\n#> INFO  [02:34:09.426] [bbotk]        cost kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:09.426] [bbotk]  -0.8161055 radial     NA 0.1789979   0.9397508        0      0\n#> INFO  [02:34:09.426] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:09.426] [bbotk]             1.429 3aa95dd5-9a22-4f26-82f6-826d332433bf\n#> INFO  [02:34:09.434] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:09.440] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:09.445] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:10.075] [mlr3] Finished benchmark\n#> INFO  [02:34:10.092] [bbotk] Result of batch 22:\n#> INFO  [02:34:10.093] [bbotk]         cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:34:10.093] [bbotk]  -0.07166682 linear     NA    NA   0.9690756        0      0            0.624\n#> INFO  [02:34:10.093] [bbotk]                                 uhash\n#> INFO  [02:34:10.093] [bbotk]  bbb78fa0-d1ba-419e-9378-12632314fa91\n#> INFO  [02:34:10.102] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:10.108] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:10.112] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:11.491] [mlr3] Finished benchmark\n#> INFO  [02:34:11.505] [bbotk] Result of batch 23:\n#> INFO  [02:34:11.507] [bbotk]       cost kernel degree     gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:34:11.507] [bbotk]  0.2154819 radial     NA 0.1292934    0.958332        0      0            1.374\n#> INFO  [02:34:11.507] [bbotk]                                 uhash\n#> INFO  [02:34:11.507] [bbotk]  5560f21c-656a-4c49-9e7c-3afac64555be\n#> INFO  [02:34:11.515] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:11.525] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:11.530] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:12.010] [mlr3] Finished benchmark\n#> INFO  [02:34:12.025] [bbotk] Result of batch 24:\n#> INFO  [02:34:12.026] [bbotk]       cost  kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:12.026] [bbotk]  0.9292742 sigmoid     NA 0.1826756   0.8441801        0      0\n#> INFO  [02:34:12.026] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:12.026] [bbotk]             0.475 2fcab667-7bc5-4a1d-89dd-73fcc0dcbfd7\n#> INFO  [02:34:12.034] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:12.040] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:12.045] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:12.541] [mlr3] Finished benchmark\n#> INFO  [02:34:12.556] [bbotk] Result of batch 25:\n#> INFO  [02:34:12.557] [bbotk]        cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:34:12.557] [bbotk]  -0.7159391 linear     NA    NA   0.9685209        0      0            0.491\n#> INFO  [02:34:12.557] [bbotk]                                 uhash\n#> INFO  [02:34:12.557] [bbotk]  3f85b22a-418c-45c2-8470-29e54f53da1c\n#> INFO  [02:34:12.566] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:12.571] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:12.576] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:13.738] [mlr3] Finished benchmark\n#> INFO  [02:34:13.753] [bbotk] Result of batch 26:\n#> INFO  [02:34:13.754] [bbotk]        cost kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:13.754] [bbotk]  -0.2707529 radial     NA 0.1142384   0.9565072        0      0\n#> INFO  [02:34:13.754] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:13.754] [bbotk]             1.158 11e3a99c-938f-420b-81b2-3b018f3a9cd0\n#> INFO  [02:34:13.762] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:13.768] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:13.773] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:14.303] [mlr3] Finished benchmark\n#> INFO  [02:34:14.318] [bbotk] Result of batch 27:\n#> INFO  [02:34:14.319] [bbotk]       cost     kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:14.319] [bbotk]  0.6745258 polynomial      3 0.1412825   0.9470498        0      0\n#> INFO  [02:34:14.319] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:14.319] [bbotk]             0.525 758a9dd5-5069-4f3f-b29a-e0845bc813fc\n#> INFO  [02:34:14.328] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:14.333] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:14.338] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:14.922] [mlr3] Finished benchmark\n#> INFO  [02:34:14.942] [bbotk] Result of batch 28:\n#> INFO  [02:34:14.944] [bbotk]        cost  kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:14.944] [bbotk]  -0.7508148 sigmoid     NA 0.1498661   0.8808159        0      0\n#> INFO  [02:34:14.944] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:14.944] [bbotk]             0.579 0bfd4b94-c640-482d-a23a-183fdf4f0d35\n#> INFO  [02:34:14.952] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:14.958] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:14.963] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:15.782] [mlr3] Finished benchmark\n#> INFO  [02:34:15.797] [bbotk] Result of batch 29:\n#> INFO  [02:34:15.798] [bbotk]        cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:34:15.798] [bbotk]  -0.8497675 sigmoid     NA 0.09646477   0.9186535        0      0\n#> INFO  [02:34:15.798] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:15.798] [bbotk]             0.815 b73a2abe-29d0-4d19-9f13-e35d3d129244\n#> INFO  [02:34:15.807] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:15.813] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:15.819] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:17.045] [mlr3] Finished benchmark\n#> INFO  [02:34:17.060] [bbotk] Result of batch 30:\n#> INFO  [02:34:17.061] [bbotk]        cost kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:17.061] [bbotk]  -0.1740692 radial     NA 0.1386397   0.9565213        0      0\n#> INFO  [02:34:17.061] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:17.061] [bbotk]             1.221 34da7d15-dc24-4dde-9356-fecae2116adf\n#> INFO  [02:34:17.073] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:17.079] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:17.084] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:17.601] [mlr3] Finished benchmark\n#> INFO  [02:34:17.616] [bbotk] Result of batch 31:\n#> INFO  [02:34:17.617] [bbotk]        cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:34:17.617] [bbotk]  -0.3421337 linear     NA    NA   0.9692404        0      0            0.513\n#> INFO  [02:34:17.617] [bbotk]                                 uhash\n#> INFO  [02:34:17.617] [bbotk]  60644bea-e524-4abc-8ca8-fd4f53f2f674\n#> INFO  [02:34:17.625] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:17.631] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:17.636] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:18.264] [mlr3] Finished benchmark\n#> INFO  [02:34:18.279] [bbotk] Result of batch 32:\n#> INFO  [02:34:18.280] [bbotk]        cost  kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:18.280] [bbotk]  -0.8117912 sigmoid     NA 0.1346607   0.8903859        0      0\n#> INFO  [02:34:18.280] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:18.280] [bbotk]             0.624 c55eb678-0f42-41e8-a0d7-a2d3750e3577\n#> INFO  [02:34:18.289] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:18.295] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:18.299] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:18.790] [mlr3] Finished benchmark\n#> INFO  [02:34:18.805] [bbotk] Result of batch 33:\n#> INFO  [02:34:18.806] [bbotk]       cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:34:18.806] [bbotk]  0.5639651 sigmoid     NA 0.02464691    0.904365        0      0\n#> INFO  [02:34:18.806] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:18.806] [bbotk]             0.485 af28278a-666c-4f28-b853-3efbca01f7cf\n#> INFO  [02:34:18.814] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:18.820] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:18.824] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:19.598] [mlr3] Finished benchmark\n#> INFO  [02:34:19.619] [bbotk] Result of batch 34:\n#> INFO  [02:34:19.620] [bbotk]       cost     kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:19.620] [bbotk]  0.5970128 polynomial      6 0.1064664   0.9081793        0      0\n#> INFO  [02:34:19.620] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:19.620] [bbotk]             0.768 96618ec0-2705-4308-a859-2b2943193a96\n#> INFO  [02:34:19.630] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:19.636] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:19.641] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:20.340] [mlr3] Finished benchmark\n#> INFO  [02:34:20.359] [bbotk] Result of batch 35:\n#> INFO  [02:34:20.360] [bbotk]        cost     kernel degree     gamma classif.auc warnings errors\n#> INFO  [02:34:20.360] [bbotk]  0.04841973 polynomial      4 0.1337475   0.9176608        0      0\n#> INFO  [02:34:20.360] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:20.360] [bbotk]             0.694 95677b2d-34d4-4ac7-946f-f6d30bdfff40\n#> INFO  [02:34:20.371] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:20.379] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:20.384] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:21.021] [mlr3] Finished benchmark\n#> INFO  [02:34:21.039] [bbotk] Result of batch 36:\n#> INFO  [02:34:21.041] [bbotk]        cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:34:21.041] [bbotk]  -0.7770614 linear     NA    NA   0.9683079        0      0             0.63\n#> INFO  [02:34:21.041] [bbotk]                                 uhash\n#> INFO  [02:34:21.041] [bbotk]  c00c8988-4c5e-424f-9d8a-628a2ce1d873\n#> INFO  [02:34:21.051] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:21.059] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:21.064] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:22.220] [mlr3] Finished benchmark\n#> INFO  [02:34:22.238] [bbotk] Result of batch 37:\n#> INFO  [02:34:22.240] [bbotk]       cost     kernel degree   gamma classif.auc warnings errors\n#> INFO  [02:34:22.240] [bbotk]  0.4114269 polynomial      6 0.13385   0.8988746        0      0\n#> INFO  [02:34:22.240] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:22.240] [bbotk]             1.151 523c421a-0ab9-43f1-89fa-5215c19d223f\n#> INFO  [02:34:22.251] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:22.257] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:22.262] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:22.744] [mlr3] Finished benchmark\n#> INFO  [02:34:22.762] [bbotk] Result of batch 38:\n#> INFO  [02:34:22.764] [bbotk]       cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:34:22.764] [bbotk]  0.7752214 sigmoid     NA 0.05379679   0.8730145        0      0\n#> INFO  [02:34:22.764] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:22.764] [bbotk]             0.477 62d13723-1784-471e-8c72-12519f49abdf\n#> INFO  [02:34:22.774] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:22.781] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:22.788] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:23.303] [mlr3] Finished benchmark\n#> INFO  [02:34:23.323] [bbotk] Result of batch 39:\n#> INFO  [02:34:23.325] [bbotk]        cost kernel degree gamma classif.auc warnings errors runtime_learners\n#> INFO  [02:34:23.325] [bbotk]  -0.5680516 linear     NA    NA   0.9692524        0      0            0.508\n#> INFO  [02:34:23.325] [bbotk]                                 uhash\n#> INFO  [02:34:23.325] [bbotk]  c5421ad2-d77f-433e-8f9f-0ba5d4e22b8c\n#> INFO  [02:34:23.333] [bbotk] Evaluating 1 configuration(s)\n#> INFO  [02:34:23.340] [mlr3] Running benchmark with 1 resampling iterations\n#> INFO  [02:34:23.344] [mlr3] Applying learner 'classif.svm' on task 'spam' (iter 1/1)\n#> INFO  [02:34:23.993] [mlr3] Finished benchmark\n#> INFO  [02:34:24.009] [bbotk] Result of batch 40:\n#> INFO  [02:34:24.011] [bbotk]       cost  kernel degree      gamma classif.auc warnings errors\n#> INFO  [02:34:24.011] [bbotk]  0.1828651 sigmoid     NA 0.01471691   0.9411093        0      0\n#> INFO  [02:34:24.011] [bbotk]  runtime_learners                                uhash\n#> INFO  [02:34:24.011] [bbotk]             0.643 a1b45290-ef44-4982-a181-27dd717fa0e5\n#> INFO  [02:34:24.030] [bbotk] Finished optimizing after 40 evaluation(s)\n#> INFO  [02:34:24.031] [bbotk] Result:\n#> INFO  [02:34:24.032] [bbotk]        cost kernel degree gamma learner_param_vals  x_domain classif.auc\n#> INFO  [02:34:24.032] [bbotk]       <num> <char>  <int> <num>             <list>    <list>       <num>\n#> INFO  [02:34:24.032] [bbotk]  -0.5680516 linear     NA    NA          <list[3]> <list[2]>   0.9692524\n```\n\n\n:::\n\n```{.r .cell-code}\n# Evaluate!\ntuned_svm$predict(spam_task, row_ids = spam_split$test)$score(msr(\n  \"classif.auc\"\n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> classif.auc \n#>   0.9702688\n```\n\n\n:::\n\n```{.r .cell-code}\n# Hyperparam winner:\ntuned_svm$tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>          cost kernel degree gamma learner_param_vals  x_domain classif.auc\n#>         <num> <char>  <int> <num>             <list>    <list>       <num>\n#> 1: -0.5680516 linear     NA    NA          <list[3]> <list[2]>   0.9692524\n```\n\n\n:::\n\n```{.r .cell-code}\n# Remember that we transformed `cost`, here's the best value on the original scale\ntuned_svm$tuning_result$x_domain\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [[1]]\n#> [[1]]$cost\n#> [1] 0.2703637\n#> \n#> [[1]]$kernel\n#> [1] \"linear\"\n```\n\n\n:::\n\n```{.r .cell-code}\nautoplot(tuned_svm$tuning_instance)\n```\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/example-svm-tuning-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n\n::: {.callout-tip title=\"SVM with categorical features\"}\nWe have not covered this so far, but if you want to tran an SVM (or many other learners) on tasks with categorical (\"nominal\") features (usually `factor` in R), we first need to encode them in a numeric format. The simplest way is to perform dummy- or one-hot encoding, and mlr3 has a whole slew of these sorts of rpeprocessing capabilities.\n\nThis works by creating a *pipeline* using the `%>>%` oeprator (not to be confused with the magrittr-pipe `%>%` you might be familiar with!). We take the `encode` pipeline operation (`PipeOp`) and stack it on top of our learner we create as usual. At the end we convert it to a regular learner, and `lrn_svm` is now a regular mlr3 learner we can use like any other, but with built-in encoding!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_svm_base <- lrn(\"classif.svm\", predict_type = \"prob\")\n\nlrn_svm <- po(\"encode\") %>>%\n  po(\"learner\", lrn_svm_base) |>\n  as_learner()\n\n# Penguin task (including categoricals!)\npenguin_task <- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\n\n# Quick demo\nlrn_svm$train(penguin_task)\nlrn_svm$predict(penguin_task)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> â”€â”€ <PredictionClassif> for 333 observations: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#>  row_ids     truth  response  prob.Adelie prob.Chinstrap prob.Gentoo\n#>        1    Adelie    Adelie 0.9897186263    0.004709601 0.005571773\n#>        2    Adelie    Adelie 0.9794937270    0.010353218 0.010153055\n#>        3    Adelie    Adelie 0.9754507758    0.014019113 0.010530111\n#>      ---       ---       ---          ---            ---         ---\n#>      331 Chinstrap Chinstrap 0.0131531135    0.979987515 0.006859371\n#>      332 Chinstrap Chinstrap 0.0049911109    0.986551962 0.008456927\n#>      333 Chinstrap Chinstrap 0.0005266358    0.993014315 0.006459049\n```\n\n\n:::\n:::\n\n\nPipelines are extremely useful and part of any reasonably complex machine learning pipeline, and to learn more you can read the [chapter in the mlr3book](https://mlr3book.mlr-org.com/chapters/chapter7/sequential_pipelines.html).\n:::\n",
    "supporting": [
      "05-svm-tuning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}