{
  "hash": "e178b53eaaf49dfeceda0db0eebaded0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"SVMs and more tuning\"\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mlr3verse) # All the mlr3 things\nlibrary(ggplot2) # For plotting\n# Silence output during tuning, mostly for cleaner output on the website\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\")\n\n# Spam Task setup\nspam_task <- tsk(\"spam\")\nset.seed(26)\n\n# train/test split\nspam_split <- partition(spam_task, ratio = 2 / 3)\n```\n:::\n\n\nGoals of this part:\n\n1.  Introduce SVMs\n2.  Tune an SVM with a more complex setup\n\n# Support Vector Machines\n\nLet's circle back to new learners and explore SVMs a little by trying out different kernels at the example of our penguin dataset we used in the beginning:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguins <- na.omit(palmerpenguins::penguins)\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point() +\n  labs(\n    title = \"Palmer Penguins\",\n    x = \"Flipper Length [mm]\",\n    y = \"Body Mass [g]\",\n    color = \"Species\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/penguins-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nSince we don't care about prediction accuracy for now, we'll use the whole dataset for training and prediction. Please only do this with toy data ðŸ™ƒ.\n\nFor the SVM algorithm itself, we use the `svm` learner from the `{e1071}` package (great name, I know) but once again use `{mlr3}`'s interface\n\nAccording to the docs (`?e1071::svm`) we have the choice of the following kernels:\n\n-   `\"linear\"`: $u'v$\n-   `\"polynomial\"`: $(\\mathtt{gamma} \\cdot u' \\cdot v + \\mathtt{coef0})^\\mathtt{degree}$\n-   `\"radial\"`: $\\exp(-\\mathtt{gamma} \\cdot |u-v|^2)$\n-   `\"sigmoid\"`: $\\tanh(\\mathtt{gamma} \\cdot u'v + \\mathtt{coef0})$\n\nWhere `gamma`, `degree`, and `coef0` are further hyperparameters.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsvm_learner <- lrn(\"classif.svm\")\n\n# What parameters do we have and what's the default kernel?\nsvm_learner$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> <ParamSet(16)>\n#> Key: <id>\n#>                  id    class lower upper nlevels          default parents\n#>              <char>   <char> <num> <num>   <num>           <list>  <list>\n#>  1:       cachesize ParamDbl  -Inf   Inf     Inf               40  [NULL]\n#>  2:   class.weights ParamUty    NA    NA     Inf           [NULL]  [NULL]\n#>  3:           coef0 ParamDbl  -Inf   Inf     Inf                0  kernel\n#>  4:            cost ParamDbl     0   Inf     Inf                1    type\n#>  5:           cross ParamInt     0   Inf     Inf                0  [NULL]\n#>  6: decision.values ParamLgl    NA    NA       2            FALSE  [NULL]\n#>  7:          degree ParamInt     1   Inf     Inf                3  kernel\n#>  8:         epsilon ParamDbl     0   Inf     Inf              0.1  [NULL]\n#>  9:          fitted ParamLgl    NA    NA       2             TRUE  [NULL]\n#> 10:           gamma ParamDbl     0   Inf     Inf   <NoDefault[0]>  kernel\n#> 11:          kernel ParamFct    NA    NA       4           radial  [NULL]\n#> 12:              nu ParamDbl  -Inf   Inf     Inf              0.5    type\n#> 13:           scale ParamUty    NA    NA     Inf             TRUE  [NULL]\n#> 14:       shrinking ParamLgl    NA    NA       2             TRUE  [NULL]\n#> 15:       tolerance ParamDbl     0   Inf     Inf            0.001  [NULL]\n#> 16:            type ParamFct    NA    NA       2 C-classification  [NULL]\n#>      value\n#>     <list>\n#>  1: [NULL]\n#>  2: [NULL]\n#>  3: [NULL]\n#>  4: [NULL]\n#>  5: [NULL]\n#>  6: [NULL]\n#>  7: [NULL]\n#>  8: [NULL]\n#>  9: [NULL]\n#> 10: [NULL]\n#> 11: [NULL]\n#> 12: [NULL]\n#> 13: [NULL]\n#> 14: [NULL]\n#> 15: [NULL]\n#> 16: [NULL]\n```\n\n\n:::\n:::\n\n\n## Your Turn!\n\nBelow you have a boilerplate for\n\na)  Creating an SVM learner and train it on the penguin dataset with 2 predictors\nb)  Plotting decision boundaries with it (using the `{mlr3}` helper function)\n\nRun the code below once to see what linear decision boundaries look like, then pick different kernels from the list above and run it again.\n\n-   What kernel would you pick just by the looks of the boundaries?\n-   How do the boundaries change if you also adjust the other hyperparameters?\n-   Try picking any other two variables as features (`penguin_task$col_info`)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguin_task <- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\npenguin_task$col_roles$feature <- c(\"body_mass_g\", \"flipper_length_mm\")\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create the learner, picking a kernel and/or other hyperparams\nsvm_learner <- lrn(\"classif.svm\", kernel = \"polynomial\", degree = 3)\n\n# Plot decision boundaries\nplot_learner_prediction(\n  learner = svm_learner,\n  task = penguin_task\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/svm-decision-boundaries-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# your code\n```\n:::\n\n\n::: {.callout-tip title=\"Example solution\" collapse =\"true\"}\n\nDirectly comparing multiple kernels with default parameters:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npenguin_task <- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\npenguin_task$col_roles$feature <- c(\"body_mass_g\", \"flipper_length_mm\")\n\n# Create a list of plots for each kernel\nplots <- lapply(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\"), \\(kernel) {\n  plot_learner_prediction(\n    learner = lrn(\"classif.svm\", kernel = kernel),\n    task = penguin_task\n  ) +\n    labs(subtitle = paste(\"SVM with \", kernel, \"kernel\"))\n})\n\n# Arrange the plots with the patchwork package\npatchwork::wrap_plots(plots, guides = \"collect\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n#> Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n#> Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n#> Raster pixels are placed at uneven horizontal intervals and will be shifted\n#> â„¹ Consider using `geom_tile()` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/svm-kernel-boundaries-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n\n## SVM-Tuning\n\nLet's try a more complex tuning experiment, based on the spam task from before.\n\nWe'll create a new SVM learner object and this time explicitly tell it which classification to do --- that's the default value anyway, but `{mlr3}` wants us to be explicit here for tuning:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsvm_learner <- lrn(\n  \"classif.svm\",\n  predict_type = \"prob\",\n  type = \"C-classification\"\n)\n```\n:::\n\n\nFirst up we'll define our search space, meaning the range of parameters we want to test out. Since `kernel` is a categorical parameter (i.e. no numbers, just names of kernels), we'll define the search space for that parameter by just passing the names of the kernels to the `p_fct()` helper function that defines `factor`-parameters in `{mlr3}`.\n\nThe interesting thing here is that some parameters are only relevant for some kernels, which we can declare via a `depends` argument:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsearch_space_svm = ps(\n  kernel = p_fct(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\")),\n  # Degree is onoly relevant if \"kernel\" is \"polynomial\"\n  degree = p_int(lower = 1, upper = 7, depends = kernel == \"polynomial\")\n)\n```\n:::\n\n\nWe can create an example design grid to inspect our setup and see that `degree` is `NA` for cases where `kernel` is not `\"polynomial\"`, just as we expected\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngenerate_design_grid(search_space_svm, resolution = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> <Design> with 6 rows:\n#>        kernel degree\n#>        <char>  <int>\n#> 1:     linear     NA\n#> 2: polynomial      1\n#> 3: polynomial      4\n#> 4: polynomial      7\n#> 5:     radial     NA\n#> 6:    sigmoid     NA\n```\n\n\n:::\n:::\n\n\n## Your Turn!\n\nThe above should get you started to...\n\n1.  Create a `search_space_svm` like above, tuning...\n\n-   `cost` from 0.1 to 1 (hint: `trafo = function(x) 10^x`)\n-   `kernel`, (like above example)\n-   `degree`, as above, **only if** `kernel == \"polynomial\"`\n-   `gamma`, from e.g. 0.01 to 0.2, **only if** `kernel` is polynomial, radial, sigmoid (hint: you can't use `kernel != \"linear\"` unfortunately, but `kernel %in% c(...)`) works\n\n2.  Use the `auto_tuner` function as previously seen with\n\n-   `svm_learner` (see above)\n-   A resampling strategy (use `\"holdout\"` if runtime is an issue)\n-   A measure (e.g. `classif.acc` or `classif.auc`)\n-   The search space you created in 1.\n-   A termination criterion (e.g. 40 evaluations)\n-   Random search as your tuning strategy\n\n3.  Train the auto-tuned learner and evaluate on the test set\n\nWhat parameter settings worked best?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# your code\n```\n:::\n\n\n::: {.callout-tip title=\"Example solution\" collapse =\"true\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsearch_space_svm = ps(\n  cost = p_dbl(-1, 1, trafo = function(x) 10^x),\n  kernel = p_fct(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\")),\n  degree = p_int(1, 7, depends = kernel == \"polynomial\"),\n  gamma = p_dbl(\n    lower = 0.01,\n    upper = 0.2,\n    depends = kernel %in% c(\"polynomial\", \"radial\", \"sigmoid\")\n  )\n)\n\ngrid <- generate_design_grid(search_space_svm, resolution = 6)\n\n# Look at grid with transformed cost param (manual way, there's probably a better one)\ngrid$data$cost_trafo <- 10^grid$data$cost\ngrid$data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>       cost     kernel degree gamma cost_trafo\n#>      <num>     <char>  <int> <num>      <num>\n#>   1:    -1     linear     NA    NA        0.1\n#>   2:    -1 polynomial      1 0.010        0.1\n#>   3:    -1 polynomial      1 0.048        0.1\n#>   4:    -1 polynomial      1 0.086        0.1\n#>   5:    -1 polynomial      1 0.124        0.1\n#>  ---                                         \n#> 290:     1    sigmoid     NA 0.048       10.0\n#> 291:     1    sigmoid     NA 0.086       10.0\n#> 292:     1    sigmoid     NA 0.124       10.0\n#> 293:     1    sigmoid     NA 0.162       10.0\n#> 294:     1    sigmoid     NA 0.200       10.0\n```\n\n\n:::\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(313)\n\ntuned_svm = auto_tuner(\n  learner = lrn(\n    \"classif.svm\",\n    predict_type = \"prob\",\n    type = \"C-classification\"\n  ),\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.auc\"),\n  search_space = search_space_svm,\n  terminator = trm(\"evals\", n_evals = 40),\n  tuner = tnr(\"random_search\")\n)\n\n# Tune!\ntuned_svm$train(spam_task, row_ids = spam_split$train)\n\n# Evaluate!\ntuned_svm$predict(spam_task, row_ids = spam_split$test)$score(msr(\n  \"classif.auc\"\n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> classif.auc \n#>   0.9702688\n```\n\n\n:::\n\n```{.r .cell-code}\n# Hyperparam winner:\ntuned_svm$tuning_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>          cost kernel degree gamma learner_param_vals  x_domain classif.auc\n#>         <num> <char>  <int> <num>             <list>    <list>       <num>\n#> 1: -0.5680516 linear     NA    NA          <list[3]> <list[2]>   0.9692524\n```\n\n\n:::\n\n```{.r .cell-code}\n# Remember that we transformed `cost`, here's the best value on the original scale\ntuned_svm$tuning_result$x_domain\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [[1]]\n#> [[1]]$cost\n#> [1] 0.2703637\n#> \n#> [[1]]$kernel\n#> [1] \"linear\"\n```\n\n\n:::\n\n```{.r .cell-code}\nautoplot(tuned_svm$tuning_instance)\n```\n\n::: {.cell-output-display}\n![](05-svm-tuning_files/figure-html/example-svm-tuning-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n:::\n\n\n::: {.callout-tip title=\"SVM with categorical features\"}\nWe have not covered this so far, but if you want to tran an SVM (or many other learners) on tasks with categorical (\"nominal\") features (usually `factor` in R), we first need to encode them in a numeric format. The simplest way is to perform dummy- or one-hot encoding, and mlr3 has a whole slew of these sorts of rpeprocessing capabilities.\n\nThis works by creating a *pipeline* using the `%>>%` oeprator (not to be confused with the magrittr-pipe `%>%` you might be familiar with!). We take the `encode` pipeline operation (`PipeOp`) and stack it on top of our learner we create as usual. At the end we convert it to a regular learner, and `lrn_svm` is now a regular mlr3 learner we can use like any other, but with built-in encoding!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlrn_svm_base <- lrn(\"classif.svm\", predict_type = \"prob\")\n\nlrn_svm <- po(\"encode\") %>>%\n  po(\"learner\", lrn_svm_base) |>\n  as_learner()\n\n# Penguin task (including categoricals!)\npenguin_task <- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\n\n# Quick demo\nlrn_svm$train(penguin_task)\nlrn_svm$predict(penguin_task)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> â”€â”€ <PredictionClassif> for 333 observations: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n#>  row_ids     truth  response  prob.Adelie prob.Chinstrap prob.Gentoo\n#>        1    Adelie    Adelie 0.9897186263    0.004709601 0.005571773\n#>        2    Adelie    Adelie 0.9794937270    0.010353218 0.010153055\n#>        3    Adelie    Adelie 0.9754507758    0.014019113 0.010530111\n#>      ---       ---       ---          ---            ---         ---\n#>      331 Chinstrap Chinstrap 0.0131531135    0.979987515 0.006859371\n#>      332 Chinstrap Chinstrap 0.0049911109    0.986551962 0.008456927\n#>      333 Chinstrap Chinstrap 0.0005266358    0.993014315 0.006459049\n```\n\n\n:::\n:::\n\n\nPipelines are extremely useful and part of any reasonably complex machine learning pipeline, and to learn more you can read the [chapter in the mlr3book](https://mlr3book.mlr-org.com/chapters/chapter7/sequential_pipelines.html).\n:::\n",
    "supporting": [
      "05-svm-tuning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}