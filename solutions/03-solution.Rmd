---
title: "03: Tuning & SVMs"
date: "`r Sys.time()`"
output: 
  html_notebook: 
    toc: yes
    theme: flatly
    number_sections: yes
editor_options: 
  chunk_output_type: console
---

```{r setup}
library(mlr3verse) # All the mlr3 things
library(mlr3viz)   # Explicitly for plot_learner_prediction()
library(ggplot2)   # For plotting

# Spam Task setup
spam_task <- tsk("spam")
set.seed(26)
spam_train <- sample(spam_task$nrow, 2/3 * spam_task$nrow)
spam_test <- setdiff(seq_len(spam_task$nrow), spam_train)
```

# Hyperparameter Tuning

## Your Turn!

### Example Code

#### `rpart` Tuning

```{r tuned-rpart}
# Tuning setup
tuned_rpart = auto_tuner(
  learner = lrn("classif.rpart", predict_type = "prob"),
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.auc"),
  search_space = ps(
    cp = p_dbl(lower = 0.001, upper = 0.03),
    maxdepth = p_int(lower = 1, upper = 30)
  ),
  terminator = trm("evals", n_evals = 40),
  tuner = tnr("random_search")
)

# Tune!
tuned_rpart$train(spam_task, row_ids = spam_split$train)

# Evaluate!
tuned_rpart$predict(spam_task, row_ids = spam_split$test)$score(msr("classif.auc"))

# Check parameter results
autoplot(tuned_rpart$tuning_instance)
```

#### `xgboost` Tuning

```{r tuned-xgboost}
# Tuning setup
tuned_xgboost = auto_tuner(
  learner = lrn("classif.xgboost", predict_type = "prob"),
  resampling = rsmp("cv", folds = 5),
  measure = msr("classif.auc"),
  search_space = ps(
    eta = p_dbl(lower = 0.001, upper = 1),
    nrounds = p_int(lower = 1, upper = 20)
  ),
  terminator = trm("evals", n_evals = 200),
  tuner = tnr("random_search")
)

# Tune!
future::plan("multisession")
tuned_xgboost$train(spam_task, row_ids = spam_split$train)

autoplot(tuned_xgboost$tuning_instance, cols_x = c("nrounds", "eta"))

# Evaluate!
tuned_xgboost$predict(spam_task, row_ids = spam_split$test)$score(msr("classif.auc"))

# Check parameter results
autoplot(tuned_xgboost$tuning_instance, type = "surface")
```

#### `ranger` Tuning

```{r tuned-ranger}
# Tuning setup
tuned_ranger = auto_tuner(
  learner = lrn("classif.ranger", predict_type = "prob"),
  resampling = rsmp("cv", folds = 5),
  measure = msr("classif.auc"),
  search_space = ps(
    num.trees = p_int(lower = 200, upper = 700)
  ),
  terminator = trm("evals", n_evals = 20),
  tuner = tnr("random_search")
)

# Tune!
tuned_ranger$train(spam_task, row_ids = spam_split$train)

# Evaluate!
tuned_ranger$predict(spam_task, row_ids = spam_split$test)$score(msr("classif.auc"))

# Check parameter results
autoplot(tuned_ranger$tuning_instance)
```

## Benchmarking all the things (with tuning)

Above we tuned all the learners individually, but often we want to tune all of them at the same time to determine which performs best overall. For that, we use `benchmark_grid()` again (like in the second notebook), but now we just give it the `AutoTuner`-style learners instead of the "normal" learners.

Since we have already set up the tuning-ready learners (`tuned_<method>` objects) above we just recycle them here, but we first reset all of them since we already tuned them and we want to start from scratch.

```{r tuning-benchmark}
tuned_knn$reset()
tuned_rpart$reset()
tuned_ranger$reset()
tuned_xgboost$reset()

tuning_learners <- list(
  tuned_knn, tuned_rpart, tuned_ranger, tuned_xgboost
)

tuning_benchmark_design <- benchmark_grid(
  tasks = spam_task,                   # Still the same task. Optional: Use list() of multiple tasks for large benchmark study
  learners = tuning_learners,          # List of AutoTune-learners
  resamplings = rsmp("cv", folds = 3)  # Outer resampling strategy
) 

# Run the benchmark and save the results
bmr <- benchmark(tuning_benchmark_design)

# Who won?
bmr$aggregate(msr("classif.auc"))
```

For statistical tests etc. on benchmark results, refer to the `mlr3benchmark` package (not included with `mlr3verse` (yet).

# Support Vector Machines?

## SVM-Tuning

### Example Code

```{r example-svm-searchspace}
search_space_svm = ps(
  cost = p_dbl(-1, 1, trafo = function(x) 10^x),
  kernel = p_fct(c("linear", "polynomial", "radial", "sigmoid")),
  degree = p_int(1, 7, depends = kernel == "polynomial"),
  gamma = p_dbl(lower = 0.01, upper = 0.2, depends = kernel %in% c("polynomial", "radial", "sigmoid"))
)

grid <- generate_design_grid(search_space_svm, resolution = 6)

# Look at grid with transformed cost param (manual way, there's probably a better one)
grid$data$cost_trafo <- 10^grid$data$cost
grid$data
```

```{r example-svm-tuning}
set.seed(313)

tuned_svm = auto_tuner(
  learner = svm_learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.auc"),
  search_space = search_space_svm,
  terminator = trm("evals", n_evals = 40),
  tuner = tnr("random_search")
)

# Tune!
tuned_svm$train(spam_task, row_ids = spam_split$train)

# Evaluate!
tuned_svm$predict(spam_task, row_ids = spam_split$test)$score(msr("classif.auc"))

# Hyperparam winner:
tuned_svm$tuning_result

# Remember that we transformed `cost`, here's the best value on the original scale
tuned_svm$tuning_result$x_domain

autoplot(tuned_svm$tuning_instance)
```
