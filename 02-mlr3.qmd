---
title: 'Introducing `{mlr3}`'
editor_options:
  chunk_output_type: console
---

```{r setup}
#| message: false
library(ggplot2) # For plotting
library(palmerpenguins) # For penguins
library(mlr3verse) # includes mlr3, mlr3learners, mlr3tuning, mlr3viz, ...
```

Goals of this part:

1.  Introduce `{mlr3}` and do everythign we did before again, but nicer


# Switching to `{mlr3}`

Now, imagine you want to try out some more hyperparameters for either `rpart()` or `kknn()` or both, and then you want to compare the two --- that would probably be kind of tedious unless you write some wrapper functions, right?
Well, luckily we're not the first people to do some machine learning!

Our code in the previous section works (hopefully), but for any given model or algorithm, there's different R packages with slightly different interfaces, and memorizing or looking up how they work can be a tedious and error-prone task, especially when we want to repeat the same general steps with each learner.
`{mlr3}` and add-on packages unify all the common tasks with a consistent interface.

## Creating a task

The task encapsulates our **data**, including which **features** we're using for learning and wich variable we use as the **target** for prediction.
Tasks can be created in [multiple ways and some standard example tasks are available in mlr3](https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html), but we're taking the long way around.

Questions a task object answers:

- What is the **task type**, what kind of prediction are we doing?
    - Here: Classification (instead of e.g. regression)

- What are we predicting on?
    - The dataset ("backend"), could be a `data.frame`, `matrix`, or a proper data base

- What variable are we trying to predict?
    - The `target` variable, here `species`

- Which variables are we using for predictions?
    - The `feature` variables, which we can adjust
    
So let's put our penguins into a task object for `{mlr3}` and inspect it:

```{r penguins-task-creation}
# Creating a classification task from our penguin data
penguin_task <- as_task_classif(
  na.omit(palmerpenguins::penguins),
  id = "penguins",
  target = "species"
)

penguin_task
```

We can poke at it a little. Try typing `penguin_task$` and hit the Tab key to trigger completions.

```{r penguins-task-creation}
# Contains our penguin dataset
penguin_task$data()
# We can ask it about e.g. our sample size and number of features
penguin_task$nrow
penguin_task$ncol
# And what the classes are
penguin_task$class_names
# What types of features do we have?
# (relevant for learner support, some don't handle factors for example!)
penguin_task$feature_types
```

We can further inspect and modify the task after the fact if we choose:

```{r penguins-task-modification}
# Display feature and target variable assignment
penguin_task$col_roles[c("feature", "target")]

# Maybe not all variables are useful for this task, let's remove some
penguin_task$set_col_roles(
  cols = c("island", "sex", "year"),
  remove_from = "feature"
)

# We can also explicitly assign the feature columns
penguin_task$col_roles$feature <- c("body_mass_g", "flipper_length_mm")

# Check what our current variables and roles are
penguin_task$col_roles[c("feature", "target")]
```

Some variables may have missing values --- if we had not excluded them in the beginning, you would find them here:

```{r penguins-task-missings}
penguin_task$missings()
```

### Train and test split

We're mixing things up with a new train/test split, just for completeness in the example.
For `{mlr3}`, we only need to save the indices / row IDs.
There's a handy `partition()` function that does the same think we did with `sample()` earlier, so let's use that!
We create another 2/3 train-test split. 2/3 is actually the default in `partition()` anyway.

```{r penguin-split}
set.seed(26)
penguin_split <- partition(penguin_task, ratio = 2 / 3)

# Contains vector of row_ids for train/test set
str(penguin_split)
```

We can now use `penguin_split$train` and `penguin_split$test` with every `mlr3` function that has a `row_ids` argument.


::: {.callout-caution}
The `row_ids` of a task are not necessarily `1:N` --- there is no guarantee they start at 1, go up to `N`, or contain all integers in between. We can generally only expect them to be unique within a task!
:::

## Picking a Learner

A learner encapsulates the fitting algorithm as well as any relevant hyperparameters, and `{mlr3}` supports a whole lot of learners to choose from.
We'll keep using `{kknn}` and `{rpart}` in the background for the classification task, but we'll use `{mlr3}` on top of them for a consistent interface.
So first, we have to find the learners we're looking for.

There's a lot more [about learners in the mlr3 book](https://mlr3book.mlr-org.com/chapters/chapter2/data_and_basic_modeling.html#sec-learners), 
but for now we're happy with the basics.

```{r learners, eval=FALSE}
# Lots of learners to choose from here:
mlr_learners
# Or as a large table:
as.data.table(mlr_learners)

# To show all classification learners (in *currently loaded* packages!)
mlr_learners$keys(pattern = "classif")

# There's also regression learner we don't need right now:
mlr_learners$keys(pattern = "regr")

# For the kknn OR rpart learners, we can use regex
mlr_learners$keys(pattern = "classif\\.(kknn|rpart)")
```

Now that we've identified our learners, we can get it quickly via the `lrn()` helper function:

```{r knn-learner}
knn_learner <- lrn("classif.kknn")
```

Most things in `mlr3` have a `$help()` method which opens the R help page:

```{r knn-learner-help}
#| eval: false
knn_learner$help()
```

What parameters does this learner have?

```{r knn-learner-params}
knn_learner$param_set
```

We can get them by name as well:

```{r knn-learner-param-ids}
knn_learner$param_set$ids()
```

Setting parameters leaves the others as default:

```{r knn-learner-configure}
knn_learner$configure(k = 5)

knn_learner$param_set
```

Identical methods to set multiple or a single hyperparam, just in case you see them in other code somewhere:

```{r knn-learner-set}
knn_learner$param_set$set_values(k = 9)
knn_learner$param_set$values <- list(k = 9)
knn_learner$param_set$values$k <- 9
```


In practice, we usually set the parameters directly when we construct the learner object:

```{r knn-learner-initialize-params}
knn_learner <- lrn("classif.kknn", k = 7)
knn_learner$param_set
```

We'll save the `{rpart}` learner for later, but all the methods are the same because they are all `Learner` objects.

## Training and evaluating

We can train the learner with default parameters once to see if it works as we expect it to.

```{r knn-train-once}
# Train learner on training data
knn_learner$train(penguin_task, row_ids = penguin_split$train)

# Look at stored model, which for knn is not very interesting
knn_learner$model
```

And we can make predictions on the test data:

```{r knn-predict-once}
knn_prediction <- knn_learner$predict(
  penguin_task,
  row_ids = penguin_split$test
)
knn_prediction
```

Our predictions are looking quite reasonable, mostly:

```{r knn-confusion-matrix}
# Confusion matrix we got via table() previously
knn_prediction$confusion
```

To calculate the prediction accuracy, we don't have to do any math in small steps.
`{mlr3}` comes with lots of measures (like accuracy) we can use, they're organized 
in the `mlr_measures` object (just like `mlr_learners`). 

We're using `"classif.acc"` here with the shorthand function `msr()`, and 
score our predictions with this measure, using the `$score()` method.

```{r knn-accuracy-once}
# Available measures for classification tasks
mlr_measures$keys(pattern = "classif")

# Scores according to the selected measure
knn_prediction$score(msr("classif.acc"))

# The inverse: Classification error (1 - accuracy)
knn_prediction$score(msr("classif.ce"))
```

As a bonus feature, `{mlr3}` also makes it easy for us to plot the decision boundaries for a two-predictor case, so we don't have to manually predict on a grid anymore.

(You can ignore any warning messages from the plot here)

```{r mlr3-plot-decision-boundaries}
plot_learner_prediction(
  learner = knn_learner,
  task = penguin_task
)
```

## Your turn!

Now that we've done the kNN fitting with `{mlr3}`, you can easily do the same thing with the `rpart`-learner!
All you have to do is switch the learner objects and give it a more fitting name.

```{r mlr3-your-turn}
# your code
```


{{< include solutions/02-1-mlr3-rpart.qmd >}}

# Useful links

- [mlr3 cheatsheet with examples](https://cheatsheets.mlr-org.com/mlr3.pdf)
- [mlr3 book](https://mlr3book.mlr-org.com/) 
