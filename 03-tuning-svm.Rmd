---
title: "03: Tuning & SVMs"
date: "`r Sys.time()`"
output: 
  html_notebook: 
    toc: yes
    theme: flatly
    number_sections: yes
---

```{r setup}
library(e1071)       # For SVMs (outside of mlr3)
library(mlr3verse)   # All the mlr3 things
library(ggplot2)     # For plotting

# Spam Task setup
spam_task <- tsk("spam")
set.seed(26)
spam_train <- sample(spam_task$nrow, 2/3 * spam_task$nrow)
spam_test <- setdiff(seq_len(spam_task$nrow), spam_train)
```

# Hyperparameter Tuning

So far we've seen four learners:

1. kNN via `{kknn}`
2. Decision Trees via `{rpart}`
3. Random Forest via `{ranger}`
4. Gradient Boosting via `{xgboost}`

We've gotten to know the first two a little, and now we'll also take a closer
look at the second two.

First we'll start doing some tuning with `{mlr3}` based on the **kNN** learner
because it's nice and simple.  
We saw that `k` is an important parameter, and it's an integer greater than 1 at least.
To tune it, we also have to make a few other decisions, also using what we learned about
resampling.  

- What's our inner resampling strategy?
- What measure to we tune on? 
- What does the parameter search space look like?
- How long to we tune? What's our *budget*?
- What's our tuning strategy?

We'll use `{mlr3}`'s [`AutoTuner`](https://mlr3book.mlr-org.com/optimization.html#autotuner)
for this because it's just so convenient:

```{r knn-tuning-setup}
# Defining a search space: k is an integer, we look in range 3 to 51
search_space = ps(
  k = p_int(lower = 3, upper = 51)
)

tuned_knn = AutoTuner$new(
  # The base learner we want to tune, optionally setting other parameters
  learner = lrn("classif.kknn", predict_type = "prob"),
  # Resampling strategy, here holdout with default split
  resampling = rsmp("holdout"),
  # Tuning measure: Maximize the AUC
  measure = msr("classif.auc"),
  # Setting the search space we defined above
  search_space = search_space,
  # Budget: Try 20 different values
  terminator = trm("evals", n_evals = 20),
  # Strategy: Randomly try parameter values in the space
  tuner = tnr("random_search")
)

# Take a look at the new tuning learner
tuned_knn
```

Now `tuned_knn` behaves the same way as any other Learner that has not been
trained on any data yet - first we have to train it on our spam training data.
The result will be the best hyperparameter confiugration of those we tried:

```{r tune-knn}
# Setting a seed so we get the same result in the workshop
set.seed(2398)
tuned_knn$train(spam_task, row_ids = spam_train)
```
In this case, we get a `k` of 32, with an AUC of 0.96 in the inner resampling 
(the holdout set during tuning).

Now we've tuned on the training set, time to evaluate on the test set, and
to shorten it a little we'll do prediction and scoring in one line:

```{r knn-eval}
tuned_knn$predict(spam_task, row_ids = spam_test)$score(msr("classif.auc"))
```
Seems like a decent result?  
Let's try to beat it with some other learner!

## Your Turn!

Above you have a boilerplate to tune your own learner.  
Start with either of the other three learners we've seen, pick one ore two hyperparameters
to tune with a reasonable budget (note we have limited time and resources),
tune on the training set and evaluate per AUC on the test set.

Some pointers:

- Consult the Learner docs to see tuning-worthy parameters:
    - `lrn("classif.xgboost")$help()` links to the `xgboost` help
    - `lrn("classif.rpart")$help()` analogously for the decision tree
    - You can also see the documentation online, e.g. https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.xgboost.html
- Parameter search spaces in `ps()` have different types, see the help at `?paradox::Domain`
    - Use `p_int()` for integers, `p_dbl()` for real-valued params etc.
- If you don't know which parameter to tune, try the following:
    - `classif.xgboost`: 
        - Important: `nrounds` (integer) (>= 1)
        - Important: `eta` (double) (0 < eta < 1)
        - Maybe: `max_depth` (integer) (< 30)
    - `classif.rpart`:
        - `cp` (double)
        - Maybe: `maxdepth` (integer) (< 30)
    - `classiff.ranger`:
        - `num.trees` (integer) (default is 500)
        - `max.depth` (integer) (ranger has no limit here :)


### Example Code

```{r tuned-xgboost}
# Tuning setup
tuned_xgboost = AutoTuner$new(
  learner = lrn("classif.xgboost", predict_type = "prob"),
  resampling = rsmp("holdout"),
  measure = msr("classif.auc"),
  search_space = ps(
    eta = p_dbl(lower = 0.001, upper = 1),
    nrounds = p_int(lower = 1, upper = 10)
  ),
  terminator = trm("evals", n_evals = 20),
  tuner = tnr("random_search")
)

# Tune!
tuned_xgboost$train(spam_task, row_ids = spam_train)

# Evaluate!
tuned_xgboost$predict(spam_task, row_ids = spam_test)$score(msr("classif.auc"))
```

```{r tuned-rpart}
# Tuning setup
tuned_rpart = AutoTuner$new(
  learner = lrn("classif.rpart", predict_type = "prob"),
  resampling = rsmp("holdout"),
  measure = msr("classif.auc"),
  search_space = ps(
    cp = p_dbl(lower = 0.001, upper = 0.5),
    maxdepth = p_int(lower = 1, upper = 25)
  ),
  terminator = trm("evals", n_evals = 20),
  tuner = tnr("random_search")
)

# Tune!
tuned_rpart$train(spam_task, row_ids = spam_train)

# Evaluate!
tuned_rpart$predict(spam_task, row_ids = spam_test)$score(msr("classif.auc"))
```

```{r tuned-ranger}
# Tuning setup
tuned_ranger = AutoTuner$new(
  learner = lrn("classif.ranger", predict_type = "prob"),
  resampling = rsmp("holdout"),
  measure = msr("classif.auc"),
  search_space = ps(
    num.trees = p_int(lower = 200, upper = 700),
    max.depth = p_int(lower = 1, upper = 25)
  ),
  terminator = trm("evals", n_evals = 20),
  tuner = tnr("random_search")
)

# Tune!
tuned_ranger$train(spam_task, row_ids = spam_train)

# Evaluate!
tuned_ranger$predict(spam_task, row_ids = spam_test)$score(msr("classif.auc"))
```

# Support Vector Machines

Let's circle back to new learners and explore SVMs a little by trying
out different kernels at the example of our penguin dataset we used in the beginning:

```{r penguins}
library(palmerpenguins)
penguins <- na.omit(penguins)

ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
  geom_point() +
  labs(
    title = "Palmer Penguins",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species"
  )
```

Since we don't care about prediction accuracy for now, we'll use the whole dataset
for training and prediction. Please only do this with toy data ðŸ™ƒ.

For the SVM algorithm itself, we use the `e1071` package (great name, I know)
with the reasonably named `svm()` function.

According to the docs (`?svm`) we have the choice of the following kernels:

- `"linear"`: $u'v$
- `"polynomial"`: $(\mathtt{gamma} \cdot u' \cdot v + \mathtt{coef0})^\mathtt{degree}$
- `"radial"`: $\exp(-\mathtt{gamma} \cdot |u-v|^2)$
- `"sigmoid"`: $\tanh(\mathtt{gamma} \cdot u'v + \mathtt{coef0})$

Where `gamma`, `degree`, and `coef0` are further hyperparameters.

## Your Turn!

Below you have a boilerplate for

a) Creating an SVM model based on the penguin dataset with 2 predictors
b) Code to plot decision boundaries with it (similar to what we did for trees)

Run the code below once to see what linear decision boundaries look like, then
pick different kernels from the list above and run it again.
What kernel would you pick just by the looks of the boundaries?

How do the boundaries change if you also adjust the other hyperparameters?

```{r svm-decision-boundaries}
# Make a model
pengu_svm  <- svm(
  species ~ flipper_length_mm + body_mass_g, 
  data = penguins, 
  kernel = "linear", # <- pick different kernels here
  degree = 3, # For "polynomial"
  gamma = 1/2, # For all except "linear". Default is 1/(number of predictors)
  coef0 = 0 # For "polynomial" and "sigmoid"
)

# Prediction grid
flipper_range <- range(penguins$flipper_length_mm)
mass_range <- range(penguins$body_mass_g)

pred_grid <- expand.grid(
  flipper_length_mm = seq(flipper_range[1], flipper_range[2], length.out = 200),
  body_mass_g = seq(mass_range[1], mass_range[2], length.out = 200)
)

# Add predictions for the grid
pred_grid$prediction <- predict(pengu_svm, newdata = pred_grid, type = "response")

# Plot decision boudnaries
ggplot(pred_grid, aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  geom_point(alpha = .1, shape = 15) +
  geom_point(data = penguins, aes(fill = species), shape = 21, color = "black") +
  labs(
    title = "Palmer Penguins",
    subtitle = "Species predicted by SVM",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species (predicted)", fill = "Species (Observed)"
  )
```

### Example Code

```{r solution-decision-boundaries}
# Iterate over kernels, make predictions, add to big prediction grid
# and bind it together to one data frame
pred_df <- purrr::map_df(c("linear", "polynomial", "radial", "sigmoid"), ~{
  mod <- svm(
    species ~ flipper_length_mm + body_mass_g, 
    data = penguins, 
    kernel = .x,
    degree = 3,
    gamma = 1/2,
    coef0 = 0 
  )
  
  # Copy prediction grid from above
  xdf <- pred_grid
  
  xdf$prediction <- predict(mod, newdata = pred_grid, type = "response")
  xdf$kernel <- .x
  
  xdf
})

ggplot(pred_df, aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  facet_wrap(vars(kernel)) +
  geom_point(alpha = .1, shape = 15) +
  geom_point(data = penguins, aes(fill = species), shape = 21, color = "black") +
  labs(
    title = "Palmer Penguins",
    subtitle = "Species predicted by different SVMs",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species (predicted)", fill = "Species (Observed)"
  ) +
  theme_minimal()
```




## SVM-Tuning (move/shorten?)

```{r spam-task}
spam_task <- tsk("spam")
```

```{r svm-learner}
# Pick our SVM learner, still using that e-numbers package
svm_learner <- lrn("classif.svm", predict_type = "prob", type = "C-classification")

# What parameters do we have?
svm_learner$param_set$ids()

# Default kernel
svm_learner$param_set$default$kernel

# Help
svm_learner$help()
```


First up we'll define our search space, meaning the range of parameters we want to test out.
Since `kernel` is a categorical parameter (i.e. no numbers, just names of kernels),
we'll define the search space for that parameter by just passing the names of
the kernels to the `p_fct()` helper function that defines `factor`-parameters in mlr3.

```{r svm-search-space-short}
search_space_svm = ps(
  kernel = p_fct(c("linear", "polynomial", "radial", "sigmoid")),
  degree = p_int(1, 7, depends = kernel == "polynomial")
)

generate_design_grid(search_space, resolution = 3)
```



```{r}
search_space_svm = ps(
  cost = p_dbl(-1, 1, trafo = function(x) 10^x),
  kernel = p_fct(c("linear", "polynomial", "radial", "sigmoid")),
  degree = p_int(1, 7, depends = kernel == "polynomial"),
  gamma = p_dbl(lower = 0.01, upper = 0.2, depends = kernel %in% c("polynomial", "radial", "sigmoid"))
)

generate_design_grid(search_space, resolution = 6)
```

```{r}
tuned_svm = AutoTuner$new(
  learner = svm_learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.auc"),
  search_space = search_space_svm,
  terminator = trm("evals", n_evals = 20),
  tuner = tnr("random_search")
)

# Tune!
tuned_svm$train(spam_task, row_ids = spam_train)

# Evaluate!
tuned_svm$predict(spam_task, row_ids = spam_test)$score(msr("classif.auc"))
```

## Bonus Feature: SVM Penguin Tuning

```{r}
search_space_svm = ps(
  cost = p_dbl(-1, 1, trafo = function(x) 10^x),
  kernel = p_fct(c("linear", "polynomial", "radial", "sigmoid")),
  degree = p_int(1, 7, depends = kernel == "polynomial"),
  gamma = p_dbl(lower = 0.01, upper = 0.2, depends = kernel %in% c("polynomial", "radial", "sigmoid"))
)

tuned_svm_penguins = AutoTuner$new(
  learner = lrn("classif.svm", type = "C-classification"),
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  search_space = search_space_svm,
  terminator = trm("evals", n_evals = 20),
  tuner = tnr("random_search")
)

# Tune on penguins
penguin_task <- TaskClassif$new(
  id = "penguins", 
  backend = na.omit(palmerpenguins::penguins), 
  target = "species"
)
penguin_task$set_col_roles(cols = c("island", "sex", "year", "bill_depth_mm", "bill_length_mm"), remove_from = "feature")

set.seed(26)
penguin_train <- sample(penguin_task$nrow, 2/3 * penguin_task$nrow)
penguin_test <- setdiff(seq_len(penguin_task$nrow), penguin_train)

tuned_svm_penguins$train(penguin_task, row_ids = penguin_train)

# Evaluate!
tuned_svm_penguins$predict(penguin_task, row_ids = penguin_test)$score(msr("classif.acc"))
```

```{r}
# Prediction grid
flipper_range <- range(penguins$flipper_length_mm)
mass_range <- range(penguins$body_mass_g)

pred_grid <- expand.grid(
  flipper_length_mm = seq(flipper_range[1], flipper_range[2], length.out = 200),
  body_mass_g = seq(mass_range[1], mass_range[2], length.out = 200)
)

# Add predictions for the grid
pred_grid$prediction <- tuned_svm_penguins$predict_newdata(newdata = pred_grid)$response

# Plot decision boudnaries
ggplot(pred_grid, aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  geom_point(alpha = .1, shape = 15) +
  geom_point(data = penguins, aes(fill = species), shape = 21, color = "black") +
  labs(
    title = "Palmer Penguins",
    subtitle = "Species predicted by tuned SVM",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species (prediction)", fill = "Species (Observed)"
  )
```

