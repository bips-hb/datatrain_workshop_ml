---
title: "03: SVMs & Neural Networks"
date: "`r Sys.time()`"
output: 
  html_notebook: 
    toc: yes
    theme: flatly
    number_sections: yes
---

```{r setup}
library(e1071)       # For SVMs (outside of mlr3)
library(mlr3verse)   # All the mlr3 things
library(ggplot2)     # For plotting
```

# Support Vector Machines

Before we start thinking about tuning in this session, let's first explore SVMs a little by trying
out different kernels at the example of our penguin dataset we used in the beginning:

```{r penguins}
library(palmerpenguins)
penguins <- na.omit(penguins)

ggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
  geom_point() +
  labs(
    title = "Palmer Penguins",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species"
  )
```

Since we don't care about prediction accuracy for now, we'll use the whole dataset
for training and prediction. Please only do this with toy data ðŸ™ƒ.

For the SVM algorithm itself, we use the `e1071` package (great name, I know)
with the reasonably named `svm()` function.

According to the docs (`?svm`) we have the choice of the following kernels:

- `"linear"`: $u'v$
- `"polynomial"`: $(\mathtt{gamma} \cdot u' \cdot v + \mathtt{coef0})^\mathtt{degree}$
- `"radial"`: $\exp(-\mathtt{gamma} \cdot |u-v|^2)$
- `"sigmoid"`: $\tanh(\mathtt{gamma} \cdot u'v + \mathtt{coef0})$

Where `gamma`, `degree`, and `coef0` are further hyperparameters (we'll stick to their default values for now).

## Your Turn!

Below you have a boilerplate for

a) Creating an SVM model based on the penguin dataset with 2 predictors
b) Code to plot decision boundaries with it (similar to what we did for trees)

Run the code below once to see what linear decision boundaries look like, then
pick different kernels from the list above and run it again.
What kernel would you pick just by the looks of the boundaries?

```{r svm-decision-boundaries}
# Make a model
pengu_svm  <- svm(
  species ~ flipper_length_mm + body_mass_g, 
  data = penguins, 
  kernel = "linear" # <- pick different kernels here
)

# Prediction grid
flipper_range <- range(penguins$flipper_length_mm)
mass_range <- range(penguins$body_mass_g)

pred_grid <- expand.grid(
  flipper_length_mm = seq(flipper_range[1], flipper_range[2], length.out = 200),
  body_mass_g = seq(mass_range[1], mass_range[2], length.out = 200)
)

# Add predictions for the grid
pred_grid$prediction <- predict(pengu_svm, newdata = pred_grid, type = "response")

# Plto decision boudnaries
ggplot(pred_grid, aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  geom_point(alpha = .1, shape = 15) +
  geom_point(data = penguins, aes(fill = species), shape = 21, color = "black") +
  labs(
    title = "Palmer Penguins",
    subtitle = "Species predicted by SVM",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species (predicted)", fill = "Species (Observed)"
  )
```

```{r solution-decision-boundaries}
# Iterate over kernels, make predictions, add to big prediction grid
# and bind it together to one data frame
pred_df <- purrr::map_df(c("linear", "polynomial", "radial", "sigmoid"), ~{
  mod <- svm(species ~ flipper_length_mm + body_mass_g, data = penguins, kernel = .x)
  
  # Copy prediction grid from above
  xdf <- pred_grid
  
  xdf$prediction <- predict(mod, newdata = pred_grid, type = "response")
  xdf$kernel <- .x
  
  xdf
})

ggplot(pred_df, aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  facet_wrap(vars(kernel)) +
  geom_point(alpha = .1, shape = 15) +
  geom_point(data = penguins, aes(fill = species), shape = 21, color = "black") +
  labs(
    title = "Palmer Penguins",
    subtitle = "Species predicted by different SVMs",
    x = "Flipper Length [mm]", y = "Body Mass [g]",
    color = "Species (predicted)", fill = "Species (Observed)"
  ) +
  theme_minimal()

```










```{r spam-task}
spam_task <- tsk("spam")
```

```{r svm-learner}
# Pick our SVM learner, still using that e-numbers package
svm_learner <- lrn("classif.svm", predict_type = "prob")

# WHat parameters do we have?
svm_learner$param_set$ids()

# Default kernel
svm_learner$param_set$default$kernel

# Help
svm_learner$help()
```

We want to try different kernels for our spam problem. We can find supported kernels
in the docs of our base learner at `?e1071::svm`:

- `"linear"`: $u'v$
- `"polynomial"`: $(\mathtt{gamma} \cdot u' \cdot v + \mathtt{coef0})^\mathtt{degree}$
- `"radial"`: $\exp(-\mathtt{gamma} \cdot |u-v|^2)$
- `"sigmoid"`: $\tanh(\mathtt{gamma} \cdot u'v + \mathtt{coef0})$

Where `gamma`, `degree`, and `coef0` are further hyperparameters (we'll stick to their default values for now).

# Hyperparameter Tuning

## SVM

First up we'll define our search space, meaning the range of parameters we want to test out.
Since `kernel` is a categorical parameter (i.e. no numbers, just names of kernels),
we'll define the search space for that parameter by just passing the names of
the kernels to the `p_fct()` helper function that defines `factor`-parameters in mlr3.

```{r svm-kernel-search-space}
search_space <- ps(
  kernel = p_fct(c("linear", "polynomial", "radial", "sigmoid"))
)

generate_design_grid(search_space)
```

Next we need to consider that in general, hyperparameter tuning could be extraordinarily
time- and resource-consuming if we were to try to exhaustively check every conceivable
combination of parameters. For that reason we decide on a "terminator", a criterion
for when we stop tuning. A simple solution (especially with our limited time and resources here)
is to just stop after a set number of evaluations.  
Like 30.  
30 is a good number.

```{r svm-terminator}
# "Stop after 30 evals"-termination criterion
evals30 = trm("evals", n_evals = 30)

trm_none <- trm("none")
```


```{r svm-tuning-instance}
instance = TuningInstanceSingleCrit$new(
  task = spam_task,
  learner = svm_learner,
  resampling = rsmp("holdout"), # Uses 2/3 ratio by default
  measure = msr("classif.auc"),
  search_space = search_space,
  terminator = trm_none
)

# Look at our setup
instance
```

```{r}
tuner <- tnr("grid_search")

tuner$optimize(instance)
```

The result of our search: The "best" parameter

```{r}
instance$result_learner_param_vals
```

We also get a list of all the benchmark iterations:

```{r}
as.data.table(instance$archive)
```

