[
  {
    "objectID": "07-importance.html",
    "href": "07-importance.html",
    "title": "Feature Importance",
    "section": "",
    "text": "library(mlr3verse) # All the mlr3 things\n\n#&gt; Loading required package: mlr3\n\nlibrary(effectplots) # For effects plotting\n\n# Penguin Task setup\npenguins &lt;- na.omit(palmerpenguins::penguins)\npenguin_task &lt;- as_task_classif(\n  penguins,\n  target = \"species\"\n)\n\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\")\nGoals of this part:",
    "crumbs": [
      "Day 2",
      "Feature Importance"
    ]
  },
  {
    "objectID": "07-importance.html#feature-importance-with-mlr3filters",
    "href": "07-importance.html#feature-importance-with-mlr3filters",
    "title": "Feature Importance",
    "section": "1.1 Feature Importance with {mlr3filters}",
    "text": "1.1 Feature Importance with {mlr3filters}\nThe mlr3filters package provides some global, marginal importance methods, meaning they consider the relationship between the target and one feature at a time.\n\nas.data.table(mlr_filters)[1:20, .(key, label)]\n\n#&gt; Key: &lt;key&gt;\n#&gt;                  key                                                    label\n#&gt;               &lt;char&gt;                                                   &lt;char&gt;\n#&gt;  1:            anova                                             ANOVA F-Test\n#&gt;  2:              auc                           Area Under the ROC Curve Score\n#&gt;  3:           boruta                                                   Burota\n#&gt;  4:         carscore                   Correlation-Adjusted coRrelation Score\n#&gt;  5:     carsurvscore          Correlation-Adjusted coRrelation Survival Score\n#&gt;  6:             cmim      Minimal Conditional Mutual Information Maximization\n#&gt;  7:      correlation                                              Correlation\n#&gt;  8:             disr                       Double Input Symmetrical Relevance\n#&gt;  9: find_correlation                                  Correlation-based Score\n#&gt; 10:       importance                                         Importance Score\n#&gt; 11: information_gain                                         Information Gain\n#&gt; 12:              jmi                                 Joint Mutual Information\n#&gt; 13:             jmim            Minimal Joint Mutual Information Maximization\n#&gt; 14:     kruskal_test                                      Kruskal-Wallis Test\n#&gt; 15:              mim                          Mutual Information Maximization\n#&gt; 16:             mrmr                     Minimum Redundancy Maximal Relevancy\n#&gt; 17:            njmim Minimal Normalised Joint Mutual Information Maximization\n#&gt; 18:      performance                                   Predictive Performance\n#&gt; 19:      permutation                                        Permutation Score\n#&gt; 20:           relief                                                   RELIEF\n#&gt;                  key                                                    label\n\n\nOne “trick” of the filters package is that it can be used to access the $importance() that some learners provide on their own, and ranger provides the impurtiy-importance and permutation feature importance (PFI). We can access either with mlr3filters directly, but note it retrains the learner:\n\nlrn_ranger &lt;- lrn(\"classif.ranger\", importance = \"impurity_corrected\")\nfilter_importance = flt(\"importance\", learner = lrn_ranger)\nfilter_importance$calculate(penguin_task)\n\nfilter_importance\n\n#&gt; &lt;FilterImportance:importance&gt;: Importance Score\n#&gt; Task Types: classif\n#&gt; Properties: missings\n#&gt; Task Properties: -\n#&gt; Packages: mlr3, mlr3learners, ranger\n#&gt; Feature types: logical, integer, numeric, character, factor, ordered\n#&gt;              feature      score\n#&gt; 1:    bill_length_mm 52.2371665\n#&gt; 2: flipper_length_mm 33.0179234\n#&gt; 3:     bill_depth_mm 27.5392018\n#&gt; 4:       body_mass_g 25.1099515\n#&gt; 5:            island 23.0539305\n#&gt; 6:               sex  0.7127981\n#&gt; 7:              year  0.1410306\n\n\nmlr3filters also provides a general implementation for PFI that retrains the learner repeatedly with one feature randomly shuffled.\n\nlrn_ranger &lt;- lrn(\"classif.ranger\")\nfilter_permutation = flt(\"permutation\", learner = lrn_ranger)\nfilter_permutation$calculate(penguin_task)\n\nfilter_permutation\n\n#&gt; &lt;FilterPermutation:permutation&gt;: Permutation Score\n#&gt; Task Types: classif\n#&gt; Properties: missings\n#&gt; Task Properties: -\n#&gt; Packages: mlr3, mlr3learners, ranger, mlr3measures\n#&gt; Feature types: logical, integer, numeric, character, factor, ordered\n#&gt;              feature       score\n#&gt; 1:    bill_length_mm  1.00000000\n#&gt; 2:            island  0.02290076\n#&gt; 3:     bill_depth_mm  0.01984733\n#&gt; 4:               sex  0.01832061\n#&gt; 5:              year -0.00610687\n#&gt; 6:       body_mass_g -0.01832061\n#&gt; 7: flipper_length_mm -0.02137405\n\n\nBut that also means we can use PFI for any other learner, such the SVM or XGBoost!",
    "crumbs": [
      "Day 2",
      "Feature Importance"
    ]
  },
  {
    "objectID": "07-importance.html#your-turn",
    "href": "07-importance.html#your-turn",
    "title": "Feature Importance",
    "section": "1.2 Your Turn!",
    "text": "1.2 Your Turn!\n\nCompute PFI with ranger using it’s built-in $importance(), using mlr3filters\nCompute PFI for an SVM using the approproate \"permutation\" filter\nComapre the two methods. Do they agree?\n\n\n# Your code\n\n\n\n\n\n\n\nmlr3 preprocessing pipelines\n\n\n\nNote that we need to use the encoding PipeOp to train the SVM of these on the penguins task, as they can’t handle categorical features automatically:\nlrn_svm &lt;- po(\"encode\") %&gt;&gt;%\n  po(\"learner\", lrn(\"classif.svm\", kernel = \"radial\", &lt;any other parameter&gt;)) |&gt;\n  as_learner()\n\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nThis is just for demonstration — we’d need to use tuned hyperparameters for the SVM for a proper comparison!\n\npenguin_task &lt;- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\n\nlrn_svm &lt;- po(\"encode\") %&gt;&gt;%\n  po(\"learner\", lrn(\"classif.svm\")) |&gt;\n  as_learner()\n\npfi_svm = flt(\"permutation\", learner = lrn_svm)\npfi_svm$calculate(penguin_task)\npfi_svm\n\n#&gt; &lt;FilterPermutation:permutation&gt;: Permutation Score\n#&gt; Task Types: classif\n#&gt; Properties: missings\n#&gt; Task Properties: -\n#&gt; Packages: mlr3, mlr3pipelines, stats, mlr3learners, e1071, mlr3measures\n#&gt; Feature types: logical, integer, numeric, character, factor, ordered,\n#&gt;   POSIXct, Date\n#&gt;              feature        score\n#&gt; 1:    bill_length_mm  1.000000000\n#&gt; 2:            island  0.041835358\n#&gt; 3:               sex -0.002699055\n#&gt; 4: flipper_length_mm -0.010796221\n#&gt; 5:     bill_depth_mm -0.010796221\n#&gt; 6:       body_mass_g -0.021592443\n#&gt; 7:              year -0.022941970\n\npfi_ranger = flt(\"importance\", learner = lrn(\"classif.ranger\", importance = \"permutation\"))\npfi_ranger$calculate(penguin_task)\npfi_ranger\n\n#&gt; &lt;FilterImportance:importance&gt;: Importance Score\n#&gt; Task Types: classif\n#&gt; Properties: missings\n#&gt; Task Properties: -\n#&gt; Packages: mlr3, mlr3learners, ranger\n#&gt; Feature types: logical, integer, numeric, character, factor, ordered\n#&gt;              feature        score\n#&gt; 1:    bill_length_mm 0.2456445948\n#&gt; 2: flipper_length_mm 0.1728776850\n#&gt; 3:            island 0.1286690809\n#&gt; 4:     bill_depth_mm 0.1154904760\n#&gt; 5:       body_mass_g 0.0755719832\n#&gt; 6:               sex 0.0124934428\n#&gt; 7:              year 0.0004331667",
    "crumbs": [
      "Day 2",
      "Feature Importance"
    ]
  },
  {
    "objectID": "07-importance.html#feature-effects-with-effectplots",
    "href": "07-importance.html#feature-effects-with-effectplots",
    "title": "Feature Importance",
    "section": "1.3 Feature Effects with {effectplots}",
    "text": "1.3 Feature Effects with {effectplots}\nGetting a number for “is this feature important” is nice, but often we want a better picture of the feature’s effect. Think of linear models and how we can interpret \\(\\beta_j\\) as the linear relationship between \\(X_j\\) and \\(Y\\) — often things aren’t linear though.\nOne approach to visualize feature effects is via Partial Dependence Plots or preferably via Accumulated Local Effect plots (ALE), which we get from the {effectplots} thankfully offers.\nLet’s recycle our ranger learner and plot some effects, using the partial dependence plot (PDP) as an example:\n\nlrn_ranger_cl &lt;- lrn(\"classif.ranger\", predict_type = \"prob\")\nlrn_ranger_cl$train(penguin_task)\n\npd_penguins &lt;- partial_dependence(\n  object = lrn_ranger_cl$model,\n  v = penguin_task$feature_names,\n  data = penguin_task$data(),\n  which_pred = \"Adelie\"\n)\n\nplot(pd_penguins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe’re doing multiclass classification here, so while our learner predicts a probability for one of each of the three target classes (Adelie, Gentoo, Chinstrap), we need to pick one for the visualization!",
    "crumbs": [
      "Day 2",
      "Feature Importance"
    ]
  },
  {
    "objectID": "07-importance.html#your-turn-possibly-for-another-time",
    "href": "07-importance.html#your-turn-possibly-for-another-time",
    "title": "Feature Importance",
    "section": "1.4 Your turn! (Possibly for another time)",
    "text": "1.4 Your turn! (Possibly for another time)\n\nUse the bike_share regression task to calculate the PDP\nStick with the ranger learner as {effectplots} supports it directly.\n\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nThe bike_sharing task is a regression task, so make sure to switch to the regression version of the learner.\nThe target is bikers, the number of people using a specific bike sharing service. More information can be found on the UCI website.\n\ntask &lt;- tsk(\"bike_sharing\")\nlrn_ranger &lt;- lrn(\"regr.ranger\")\nlrn_ranger$train(task)\n\npd_bikeshare &lt;- partial_dependence(\n  object = lrn_ranger$model,\n  v = task$feature_names,\n  data = task$data()\n)\n\nplot(pd_bikeshare)",
    "crumbs": [
      "Day 2",
      "Feature Importance"
    ]
  },
  {
    "objectID": "05-svm-tuning.html",
    "href": "05-svm-tuning.html",
    "title": "SVMs and more tuning",
    "section": "",
    "text": "library(mlr3verse) # All the mlr3 things\nlibrary(ggplot2) # For plotting\n# Silence output during tuning, mostly for cleaner output on the website\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\")\n\n# Spam Task setup\nspam_task &lt;- tsk(\"spam\")\nset.seed(26)\n\n# train/test split\nspam_split &lt;- partition(spam_task, ratio = 2 / 3)\nGoals of this part:",
    "crumbs": [
      "Day 2",
      "SVMs and more tuning"
    ]
  },
  {
    "objectID": "05-svm-tuning.html#your-turn",
    "href": "05-svm-tuning.html#your-turn",
    "title": "SVMs and more tuning",
    "section": "1.1 Your Turn!",
    "text": "1.1 Your Turn!\nBelow you have a boilerplate for\n\nCreating an SVM learner and train it on the penguin dataset with 2 predictors\nPlotting decision boundaries with it (using the {mlr3} helper function)\n\nRun the code below once to see what linear decision boundaries look like, then pick different kernels from the list above and run it again.\n\nWhat kernel would you pick just by the looks of the boundaries?\nHow do the boundaries change if you also adjust the other hyperparameters?\nTry picking any other two variables as features (penguin_task$col_info)\n\n\npenguin_task &lt;- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\npenguin_task$col_roles$feature &lt;- c(\"body_mass_g\", \"flipper_length_mm\")\n\n\n# Create the learner, picking a kernel and/or other hyperparams\nsvm_learner &lt;- lrn(\"classif.svm\", kernel = \"polynomial\", degree = 3)\n\n# Plot decision boundaries\nplot_learner_prediction(\n  learner = svm_learner,\n  task = penguin_task\n)\n\n#&gt; Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.\n\n\n\n\n\n\n\n\n\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nDirectly comparing multiple kernels with default parameters:\n\npenguin_task &lt;- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\npenguin_task$col_roles$feature &lt;- c(\"body_mass_g\", \"flipper_length_mm\")\n\n# Create a list of plots for each kernel\nplots &lt;- lapply(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\"), \\(kernel) {\n  plot_learner_prediction(\n    learner = lrn(\"classif.svm\", kernel = kernel),\n    task = penguin_task\n  ) +\n    labs(subtitle = paste(\"SVM with \", kernel, \"kernel\"))\n})\n\n# Arrange the plots with the patchwork package\npatchwork::wrap_plots(plots, guides = \"collect\")\n\n#&gt; Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.\n#&gt; Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.\n#&gt; Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.\n#&gt; Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.",
    "crumbs": [
      "Day 2",
      "SVMs and more tuning"
    ]
  },
  {
    "objectID": "05-svm-tuning.html#svm-tuning",
    "href": "05-svm-tuning.html#svm-tuning",
    "title": "SVMs and more tuning",
    "section": "1.2 SVM-Tuning",
    "text": "1.2 SVM-Tuning\nLet’s try a more complex tuning experiment, based on the spam task from before.\nWe’ll create a new SVM learner object and this time explicitly tell it which classification to do — that’s the default value anyway, but {mlr3} wants us to be explicit here for tuning:\n\nsvm_learner &lt;- lrn(\n  \"classif.svm\",\n  predict_type = \"prob\",\n  type = \"C-classification\"\n)\n\nFirst up we’ll define our search space, meaning the range of parameters we want to test out. Since kernel is a categorical parameter (i.e. no numbers, just names of kernels), we’ll define the search space for that parameter by just passing the names of the kernels to the p_fct() helper function that defines factor-parameters in {mlr3}.\nThe interesting thing here is that some parameters are only relevant for some kernels, which we can declare via a depends argument:\n\nsearch_space_svm = ps(\n  kernel = p_fct(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\")),\n  # Degree is only relevant if \"kernel\" is \"polynomial\"\n  degree = p_int(lower = 1, upper = 7, depends = kernel == \"polynomial\")\n)\n\nWe can create an example design grid to inspect our setup and see that degree is NA for cases where kernel is not \"polynomial\", just as we expected\n\ngenerate_design_grid(search_space_svm, resolution = 3)\n\n#&gt; &lt;Design&gt; with 6 rows:\n#&gt;        kernel degree\n#&gt;        &lt;char&gt;  &lt;int&gt;\n#&gt; 1:     linear     NA\n#&gt; 2: polynomial      1\n#&gt; 3: polynomial      4\n#&gt; 4: polynomial      7\n#&gt; 5:     radial     NA\n#&gt; 6:    sigmoid     NA",
    "crumbs": [
      "Day 2",
      "SVMs and more tuning"
    ]
  },
  {
    "objectID": "05-svm-tuning.html#your-turn-1",
    "href": "05-svm-tuning.html#your-turn-1",
    "title": "SVMs and more tuning",
    "section": "1.3 Your Turn!",
    "text": "1.3 Your Turn!\nThe above should get you started to…\n\nCreate a search_space_svm like above, tuning…\n\n\ncost from 0.1 to 1 (hint: logscale = TRUE or e.g. trafo = function(x) 10^x)\nkernel, (like above example)\ndegree, as above, only if kernel == \"polynomial\"\ngamma, from e.g. 0.01 to 0.2, only if kernel is polynomial, radial, sigmoid (hint: you can’t use kernel != \"linear\" unfortunately, but kernel %in% c(...)) works\n\n\nUse the auto_tuner function as previously seen with\n\n\nsvm_learner (see above)\nA resampling strategy (use \"holdout\" if runtime is an issue)\nA measure (e.g. classif.acc or classif.auc)\nThe search space you created in 1.\nA termination criterion (e.g. 40 evaluations)\nRandom search as your tuning strategy\n\n\nTrain the auto-tuned learner and evaluate on the test set\n\nWhat parameter settings worked best?\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\n\nsearch_space_svm = ps(\n  cost = p_dbl(-1, 1, trafo = function(x) 10^x),\n  kernel = p_fct(c(\"linear\", \"polynomial\", \"radial\", \"sigmoid\")),\n  degree = p_int(1, 7, depends = kernel == \"polynomial\"),\n  gamma = p_dbl(\n    lower = 0.01,\n    upper = 0.2,\n    depends = kernel %in% c(\"polynomial\", \"radial\", \"sigmoid\")\n  )\n)\n\ngrid &lt;- generate_design_grid(search_space_svm, resolution = 6)\n\n# Look at grid with transformed cost param (manual way, there's probably a better one)\ngrid$data$cost_trafo &lt;- 10^grid$data$cost\ngrid$data\n\n#&gt;       cost     kernel degree gamma cost_trafo\n#&gt;      &lt;num&gt;     &lt;char&gt;  &lt;int&gt; &lt;num&gt;      &lt;num&gt;\n#&gt;   1:    -1     linear     NA    NA        0.1\n#&gt;   2:    -1 polynomial      1 0.010        0.1\n#&gt;   3:    -1 polynomial      1 0.048        0.1\n#&gt;   4:    -1 polynomial      1 0.086        0.1\n#&gt;   5:    -1 polynomial      1 0.124        0.1\n#&gt;  ---                                         \n#&gt; 290:     1    sigmoid     NA 0.048       10.0\n#&gt; 291:     1    sigmoid     NA 0.086       10.0\n#&gt; 292:     1    sigmoid     NA 0.124       10.0\n#&gt; 293:     1    sigmoid     NA 0.162       10.0\n#&gt; 294:     1    sigmoid     NA 0.200       10.0\n\n\n\nset.seed(313)\n\ntuned_svm = auto_tuner(\n  learner = lrn(\n    \"classif.svm\",\n    predict_type = \"prob\",\n    type = \"C-classification\"\n  ),\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.auc\"),\n  search_space = search_space_svm,\n  terminator = trm(\"evals\", n_evals = 40),\n  tuner = tnr(\"random_search\")\n)\n\n# Tune!\ntuned_svm$train(spam_task, row_ids = spam_split$train)\n\n# Evaluate!\ntuned_svm$predict(spam_task, row_ids = spam_split$test)$score(msr(\n  \"classif.auc\"\n))\n\n#&gt; classif.auc \n#&gt;   0.9702688\n\n# Hyperparam winner:\ntuned_svm$tuning_result\n\n#&gt;          cost kernel degree gamma learner_param_vals  x_domain classif.auc\n#&gt;         &lt;num&gt; &lt;char&gt;  &lt;int&gt; &lt;num&gt;             &lt;list&gt;    &lt;list&gt;       &lt;num&gt;\n#&gt; 1: -0.5680516 linear     NA    NA          &lt;list[3]&gt; &lt;list[2]&gt;   0.9692524\n\n# Remember that we transformed `cost`, here's the best value on the original scale\ntuned_svm$tuning_result$x_domain\n\n#&gt; [[1]]\n#&gt; [[1]]$cost\n#&gt; [1] 0.2703637\n#&gt; \n#&gt; [[1]]$kernel\n#&gt; [1] \"linear\"\n\nautoplot(tuned_svm$tuning_instance)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSVM with categorical features\n\n\n\nWe have not covered this so far, but if you want to tran an SVM (or many other learners) on tasks with categorical (“nominal”) features (usually factor in R), we first need to encode them in a numeric format. The simplest way is to perform dummy- or one-hot encoding, and mlr3 has a whole slew of these sorts of rpeprocessing capabilities.\nThis works by creating a pipeline using the %&gt;&gt;% oeprator (not to be confused with the magrittr-pipe %&gt;% you might be familiar with!). We take the encode pipeline operation (PipeOp) and stack it on top of our learner we create as usual. At the end we convert it to a regular learner, and lrn_svm is now a regular mlr3 learner we can use like any other, but with built-in encoding!\n\nlrn_svm_base &lt;- lrn(\"classif.svm\", predict_type = \"prob\")\n\nlrn_svm &lt;- po(\"encode\") %&gt;&gt;%\n  po(\"learner\", lrn_svm_base) |&gt;\n  as_learner()\n\n# Penguin task (including categoricals!)\npenguin_task &lt;- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  target = \"species\"\n)\n\n# Quick demo\nlrn_svm$train(penguin_task)\nlrn_svm$predict(penguin_task)\n\n#&gt; \n#&gt; ── &lt;PredictionClassif&gt; for 333 observations: ───────────────────────────────────\n#&gt;  row_ids     truth  response  prob.Adelie prob.Chinstrap prob.Gentoo\n#&gt;        1    Adelie    Adelie 0.9897186263    0.004709601 0.005571773\n#&gt;        2    Adelie    Adelie 0.9794937270    0.010353218 0.010153055\n#&gt;        3    Adelie    Adelie 0.9754507758    0.014019113 0.010530111\n#&gt;      ---       ---       ---          ---            ---         ---\n#&gt;      331 Chinstrap Chinstrap 0.0131531135    0.979987515 0.006859371\n#&gt;      332 Chinstrap Chinstrap 0.0049911109    0.986551962 0.008456927\n#&gt;      333 Chinstrap Chinstrap 0.0005266358    0.993014315 0.006459049\n\n\nPipelines are extremely useful and part of any reasonably complex machine learning pipeline, and to learn more you can read the chapter in the mlr3book.",
    "crumbs": [
      "Day 2",
      "SVMs and more tuning"
    ]
  },
  {
    "objectID": "03-resampling-rf-boosting.html",
    "href": "03-resampling-rf-boosting.html",
    "title": "Resampling, Random Forest & Boosting",
    "section": "",
    "text": "library(mlr3verse) # Loads all the mlr3 stuff\nlibrary(ggplot2) # For plotting\n\n# Just telling mlr3 to be quiet unless something broke\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\")\nGoals of this part:",
    "crumbs": [
      "Day 1",
      "Resampling, Random Forest & Boosting"
    ]
  },
  {
    "objectID": "03-resampling-rf-boosting.html#your-turn",
    "href": "03-resampling-rf-boosting.html#your-turn",
    "title": "Resampling, Random Forest & Boosting",
    "section": "1.1 Your turn!",
    "text": "1.1 Your turn!\nExplore the task a little (you can use its built-in methods spam_task$...) to check the data, get column types, the dataset dimensions etc. Think about this as a new analysis problem, so what do we need to know here?\n(If you’d like a simpler overview, you can read the help with spam_task$help())",
    "crumbs": [
      "Day 1",
      "Resampling, Random Forest & Boosting"
    ]
  },
  {
    "objectID": "03-resampling-rf-boosting.html#one-more-thing-measures",
    "href": "03-resampling-rf-boosting.html#one-more-thing-measures",
    "title": "Resampling, Random Forest & Boosting",
    "section": "2.1 One more thing: Measures",
    "text": "2.1 One more thing: Measures\nSo far we’ve always used the accuracy, i.e. the proportion of correct classifications as our measure. For a problem such as spam detection that might not be the best choice, because it might be better to consider the probability that an e-mail is spam and maybe adjust the threshold at which we start rejecting mail.\nFor a class prediction we might say that if prob(is_spam) &gt; 0.5 the message is classified as spam, but maybe we’d rather be more conservative and only consider a message to be spam at a probability over, let’s say, 70%. This will change the relative amounts of true and false positives and negatives:\n\nknn_learner &lt;- lrn(\"classif.kknn\", predict_type = \"prob\", k = 13)\n\nset.seed(123)\nspam_split &lt;- partition(spam_task)\nknn_learner$train(spam_task, spam_split$train)\nknn_pred &lt;- knn_learner$predict(spam_task, spam_split$test)\n\n# Measures: True Positive Rate (Sensitivity) and True Negative Rate (1 - Specificity)\nmeasures &lt;- msrs(c(\"classif.tpr\", \"classif.tnr\"))\nknn_pred$confusion\n\n#&gt;          truth\n#&gt; response  spam nonspam\n#&gt;   spam     508      43\n#&gt;   nonspam   95     872\n\nknn_pred$score(measures)\n\n#&gt; classif.tpr classif.tnr \n#&gt;   0.8424544   0.9530055\n\n# Threshold of 70% probability of spam:\nknn_pred$set_threshold(0.7)\nknn_pred$confusion\n\n#&gt;          truth\n#&gt; response  spam nonspam\n#&gt;   spam     446      20\n#&gt;   nonspam  157     895\n\nknn_pred$score(measures)\n\n#&gt; classif.tpr classif.tnr \n#&gt;   0.7396352   0.9781421\n\n# If we were happy with only 20% probability of spam to mark a message as spam:\nknn_pred$set_threshold(0.2)\nknn_pred$confusion\n\n#&gt;          truth\n#&gt; response  spam nonspam\n#&gt;   spam     570     161\n#&gt;   nonspam   33     754\n\nknn_pred$score(measures)\n\n#&gt; classif.tpr classif.tnr \n#&gt;   0.9452736   0.8240437\n\n\nFor a better analysis than just manually trying out different thresholds, we can use ROC curves.\nTo do so, we first have to adjust our Learner to predict the spam probability instead of already simplifying the prediction to \"spam\" or \"nonspam\". We use the autoplot() function based on the prediction, specifying type = \"roc\" to give us an ROC curve:\n\nautoplot(knn_pred, type = \"roc\")\n\n\n\n\n\n\n\n\nThis gives us the false positive rate (FPR, “1 - Specificity”) and the Sensitivity (or true positive rate, TPR) for our binary classification example. “Positive” here means “the e-mail is spam”. If our classification model was basically a random coin flip, we would expect the curve to be the diagonal (depicted in grey in the plot). Everything in the upper-left is at least better than random.\nTo condense this to a single number, we use the AUC, the area under the (ROC) curve. If this AUC is 0.5, our model is basically a coin toss — and if it’s 1, that means our model is perfect, which is usually too good to be true and means we overfit in some way or the data is weird.\nTo get the AUC we use msr(\"classif.auc\") instead of \"classif.acc\" going forward.",
    "crumbs": [
      "Day 1",
      "Resampling, Random Forest & Boosting"
    ]
  },
  {
    "objectID": "03-resampling-rf-boosting.html#your-turn-1",
    "href": "03-resampling-rf-boosting.html#your-turn-1",
    "title": "Resampling, Random Forest & Boosting",
    "section": "2.2 Your Turn!",
    "text": "2.2 Your Turn!\n\nRepeat the same resampling steps for the {rpart} decision tree learner. (Resample with 5-fold CV, evaluate based on test accuracy)\n\n\nDoes it fare better than kNN with default parameters?\n\n\nRepeat either learner resampling with different hyperparameters\n{mlr3viz} provides alternatives to the ROC curve, which are described in the help page ?autoplot.PredictionClassif. Experiment with precision recall and threshold curves. Which would you consider most useful?\n\nThis is technically peck-and-find hyperparameter tuning which we’ll do in a more convenient (and methodologically sound) way in the next part :)\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nThe idea would be to re-run this code chunk with different hyperparameters:\n\nrr &lt;- resample(\n  task = spam_task,\n  # Important: set predict_type to \"prob\", set other parameters as desired.\n  learner = lrn(\n    \"classif.rpart\",\n    predict_type = \"prob\",\n    maxdepth = 15,\n    cp = 0.003\n  ),\n  resampling = rsmp(\"cv\", folds = 3)\n)\n\nrr$score(msr(\"classif.acc\"))[, .(classif.acc)]\n\n#&gt;    classif.acc\n#&gt;          &lt;num&gt;\n#&gt; 1:   0.9022164\n#&gt; 2:   0.9211213\n#&gt; 3:   0.9197652\n\n\nROC curve based on resampling iterations:\n\nautoplot(rr, type = \"roc\")\n\n\n\n\n\n\n\nrr$aggregate(msr(\"classif.auc\"))\n\n#&gt; classif.auc \n#&gt;    0.934748\n\n\nAlternatives to ROC: Precision-Recall curve (prc) and a threshold-error curve — all three can be very useful depending on your specific classification problem!\n\nautoplot(rr, type = \"prc\")\n\n\n\n\n\n\n\n# Threshold plot doesn't work on resampling result, but on prediction objects!\nautoplot(rr$prediction(), type = \"threshold\")",
    "crumbs": [
      "Day 1",
      "Resampling, Random Forest & Boosting"
    ]
  },
  {
    "objectID": "03-resampling-rf-boosting.html#your-turn-2",
    "href": "03-resampling-rf-boosting.html#your-turn-2",
    "title": "Resampling, Random Forest & Boosting",
    "section": "3.1 Your Turn!",
    "text": "3.1 Your Turn!\nSince we have a binary classification problem, we might even get away with using plain old logistic regression.\nInstead of benchmarking against the featureless learner, compare kNN and decision trees to the logistic regression learner \"classif.log_reg\" without any hyperparameters.\nDo our fancy ML methods beat the good old GLM? Use the best hyperparameter settings for kNN and rpart you have found so far\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\n\nlearners &lt;- list(\n  lrn(\"classif.kknn\", id = \"knn\", predict_type = \"prob\", k = 25),\n  lrn(\"classif.rpart\", id = \"tree\", predict_type = \"prob\", maxdepth = 11, cp = 0.0036),\n  lrn(\"classif.log_reg\", id = \"LogReg\", predict_type = \"prob\")\n) \n\ndesign &lt;- benchmark_grid(\n  tasks = spam_task,       # Still the same task\n  learners = learners,     # The new list of learners\n  resamplings = rsmp(\"cv\", folds = 3)  # Same resampling strategy as before\n) \n\n# Run the benchmark and save the results\nbmr &lt;- benchmark(design)\n\n#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nautoplot(bmr, type = \"roc\")\n\n\n\n\n\n\n\nbmr$aggregate(msr(\"classif.auc\"))[, .(learner_id, classif.auc)]\n\n#&gt;    learner_id classif.auc\n#&gt;        &lt;char&gt;       &lt;num&gt;\n#&gt; 1:        knn   0.9654111\n#&gt; 2:       tree   0.9276236\n#&gt; 3:     LogReg   0.9707810",
    "crumbs": [
      "Day 1",
      "Resampling, Random Forest & Boosting"
    ]
  },
  {
    "objectID": "03-resampling-rf-boosting.html#your-turn-3",
    "href": "03-resampling-rf-boosting.html#your-turn-3",
    "title": "Resampling, Random Forest & Boosting",
    "section": "4.1 Your Turn!",
    "text": "4.1 Your Turn!\nUse the benchmark setup from above and switch the kknn and rpart learners with the Random Forest and Boosting learners.\nMaybe switch to holdout resampling to speed the process up a little and make sure to set nrounds to something greater than 1 for xgboost.\nWhat about now? Can we beat logistic regression?\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\n\nlearners &lt;- list(\n  lrn(\"classif.ranger\", id = \"forest\", predict_type = \"prob\"),\n  lrn(\"classif.xgboost\", id = \"xgboost\", predict_type = \"prob\", nrounds = 5),\n  lrn(\"classif.log_reg\", id = \"LogReg\", predict_type = \"prob\")\n) \n\ndesign &lt;- benchmark_grid(\n  tasks = spam_task,       # Still the same task\n  learners = learners,     # The new list of learners\n  resamplings = rsmp(\"cv\", folds = 3)\n) \n\n# Run the benchmark and save the results\nbmr &lt;- benchmark(design)\n\n#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n#&gt; Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nautoplot(bmr, type = \"roc\")\n\n\n\n\n\n\n\nbmr$aggregate(msr(\"classif.auc\"))[, .(learner_id, classif.auc)]\n\n#&gt;    learner_id classif.auc\n#&gt;        &lt;char&gt;       &lt;num&gt;\n#&gt; 1:     forest   0.9847315\n#&gt; 2:    xgboost   0.9703650\n#&gt; 3:     LogReg   0.9696380",
    "crumbs": [
      "Day 1",
      "Resampling, Random Forest & Boosting"
    ]
  },
  {
    "objectID": "01-knn-trees.html",
    "href": "01-knn-trees.html",
    "title": "kNN & Trees",
    "section": "",
    "text": "library(ggplot2) # For plotting\nlibrary(kknn) # For kNN learner\nlibrary(rpart) # For decision tree learners\nlibrary(palmerpenguins) # For penguins\nGoals of this part:",
    "crumbs": [
      "Day 1",
      "kNN & Trees"
    ]
  },
  {
    "objectID": "01-knn-trees.html#knn",
    "href": "01-knn-trees.html#knn",
    "title": "kNN & Trees",
    "section": "2.1 kNN",
    "text": "2.1 kNN\nLet’s start with the nearest-neighbor approach via the {kknn} package. It takes a formula argument like you may know from lm() and other common modeling functions in R, where the format is predict_this ~ on_this + and_that + ....\n\nknn_penguins &lt;- kknn(\n  formula = species ~ flipper_length_mm + body_mass_g,\n  k = 3, # Hyperparameter: How many neighbors to consider\n  train = penguins_train, # Training data used to make predictions\n  test = penguins_test # Data to make predictions on\n)\n\n# Peek at the predictions, one row per observation in test data\nhead(knn_penguins$prob)\n\n#&gt;         Adelie Chinstrap Gentoo\n#&gt; [1,] 1.0000000 0.0000000      0\n#&gt; [2,] 0.3333333 0.6666667      0\n#&gt; [3,] 1.0000000 0.0000000      0\n#&gt; [4,] 0.3333333 0.6666667      0\n#&gt; [5,] 1.0000000 0.0000000      0\n#&gt; [6,] 1.0000000 0.0000000      0\n\n\nTo get an idea of how well our predictions fit, we add them to our original test data and compare observed (true) and predicted species:\n\n# Add predictions to the test dataset\npenguins_test$knn_predicted_species &lt;- fitted(knn_penguins)\n\n# Rows: True species, columns: predicted species\ntable(\n  penguins_test$species,\n  penguins_test$knn_predicted_species,\n  dnn = c(\"Observed\", \"Predicted\")\n)\n\n#&gt;            Predicted\n#&gt; Observed    Adelie Chinstrap Gentoo\n#&gt;   Adelie        38         8      1\n#&gt;   Chinstrap     12         8      4\n#&gt;   Gentoo         0         1     39\n\n\nProportion of correct predictions (“accuracy”)…\n\nmean(penguins_test$species == penguins_test$knn_predicted_species)\n\n#&gt; [1] 0.7657658\n\n\n…and incorrect predictions (classification error):\n\nmean(penguins_test$species != penguins_test$knn_predicted_species)\n\n#&gt; [1] 0.2342342\n\n\n\n\n\n\n\n\nR shortcut\n\n\n\nLogical comparison gives logical vector of TRUE/FALSE, which can be used like 1 / 0 for mathematical operations, so we can sum up cases where observed == predicted (=&gt; correct classifications) and divide by N for the proportion, i.e. calculate the proportion of correct predictions, the accuracy.",
    "crumbs": [
      "Day 1",
      "kNN & Trees"
    ]
  },
  {
    "objectID": "01-knn-trees.html#your-turn",
    "href": "01-knn-trees.html#your-turn",
    "title": "kNN & Trees",
    "section": "2.2 Your turn!",
    "text": "2.2 Your turn!\nAbove you have working code for an acceptable but not great kNN model. Can you make it even better? Can you change something to make it worse?\nSome things to try:\n\nTry different predictors, maybe leave some out\n\nWhich seem to work best?\n\nTry using all available predictors (formula = species ~ .)\n\nWould you recommend doing that? Does it work well?\n\nTry different k values. Is higher == better? (You can stick to odd numbers)\n\nAfter you’ve tried a couple k’s, does it get cumbersome yet?\n\n\n\n# your code\nknn_penguins &lt;- kknn(\n  formula = species ~ .,\n  k = 7, # Hyperparameter: How many neighbors to consider\n  train = penguins_train, # Training data used to make predictions\n  test = penguins_test # Data to make predictions on\n)\npenguins_test$knn_predicted_species &lt;- fitted(knn_penguins)\nmean(penguins_test$species == penguins_test$knn_predicted_species)\n\n#&gt; [1] 1\n\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nAlready perfect accuracy with multiple predictors, not so interesting\n\nknn_penguins &lt;- kknn(\n  formula = species ~ flipper_length_mm + body_mass_g + bill_length_mm + bill_depth_mm,\n  k = 5,\n  train = penguins_train,\n  test = penguins_test\n)\n\npenguins_test$knn_predicted_species &lt;- fitted(knn_penguins)\nmean(penguins_test$species == penguins_test$knn_predicted_species)\n\n#&gt; [1] 1\n\n\nThe “try a bunch of k”-shortcut function (using less features to be moderately interesting):\n\nknn_try_k &lt;- function(k) {\n  knn_penguins &lt;- kknn::kknn(\n    formula = species ~ flipper_length_mm + body_mass_g + bill_depth_mm,\n    k = k,\n    train = penguins_train,\n    test = penguins_test\n  )\n\n  penguins_test$knn_predicted_species &lt;- fitted(knn_penguins)\n  acc &lt;- mean(penguins_test$species == penguins_test$knn_predicted_species)\n  \n  data.frame(k = k, accuracy = acc)\n}\n\n# Call function ^ with k = 1 through 10, collect result as data.frame\nk_result &lt;- do.call(rbind, lapply(1:10, knn_try_k))\n\nggplot(k_result, aes(x = k, y = accuracy)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:10) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    title = \"kNN test accuracy on penguin dataset\",\n    x = \"k\", y = \"Test accuracy\"\n  ) +\n  theme_minimal() +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\n\n\n\nThis is a cumbersome way to find the “best” k though — we’ll learn about the better ways later!\n(We basically did a grid search across k here)",
    "crumbs": [
      "Day 1",
      "kNN & Trees"
    ]
  },
  {
    "objectID": "01-knn-trees.html#growing-a-decision-tree",
    "href": "01-knn-trees.html#growing-a-decision-tree",
    "title": "kNN & Trees",
    "section": "2.3 Growing a decision tree",
    "text": "2.3 Growing a decision tree\nNow that we’ve played around with kNN a little, let’s grow some trees! We’ll use the {rpart} (Recursive Partitioning) package and start with the same model specification as before and use the default parameters.\n\nrpart_penguins &lt;- rpart(\n  formula = species ~ flipper_length_mm + body_mass_g,\n  data = penguins_train, # Train data\n  method = \"class\", # Grow a classification tree (don't change this for now)\n)\n\nThe nice thing about a single tree is that you can just look at it and know exactly what it did:\n\nrpart_penguins\n\n#&gt; n= 222 \n#&gt; \n#&gt; node), split, n, loss, yval, (yprob)\n#&gt;       * denotes terminal node\n#&gt; \n#&gt;  1) root 222 123 Adelie (0.445945946 0.198198198 0.355855856)  \n#&gt;    2) flipper_length_mm&lt; 206.5 141  43 Adelie (0.695035461 0.297872340 0.007092199)  \n#&gt;      4) flipper_length_mm&lt; 194.5 96  19 Adelie (0.802083333 0.197916667 0.000000000) *\n#&gt;      5) flipper_length_mm&gt;=194.5 45  22 Chinstrap (0.466666667 0.511111111 0.022222222)  \n#&gt;       10) body_mass_g&gt;=3762.5 29  12 Adelie (0.586206897 0.379310345 0.034482759)  \n#&gt;         20) flipper_length_mm&lt; 200.5 16   3 Adelie (0.812500000 0.187500000 0.000000000) *\n#&gt;         21) flipper_length_mm&gt;=200.5 13   5 Chinstrap (0.307692308 0.615384615 0.076923077) *\n#&gt;       11) body_mass_g&lt; 3762.5 16   4 Chinstrap (0.250000000 0.750000000 0.000000000) *\n#&gt;    3) flipper_length_mm&gt;=206.5 81   3 Gentoo (0.012345679 0.024691358 0.962962963) *\n\n\nLooking at the tree as a… tree.\n\nplot(rpart_penguins)\ntext(rpart_penguins)\n\n\n\n\n\n\n\n\nMuch nicer to use the rpart.plot package though\n\nlibrary(rpart.plot)\nrpart.plot(rpart_penguins)\n\n\n\n\n\n\n\n\nIf we want to know how accurate we are with our model we need to make predictions on our test data manually:\n\nrpart_predictions &lt;- predict(\n  rpart_penguins, # The model we just fit\n  newdata = penguins_test, # New data to predict species on\n  type = \"class\" # We want class predictions (the species), not probabilities\n)\n\npenguins_test$rpart_predicted_species &lt;- rpart_predictions\n\n# Same procedure as with kNN before\ntable(penguins_test$species, penguins_test$rpart_predicted_species)\n\n#&gt;            \n#&gt;             Adelie Chinstrap Gentoo\n#&gt;   Adelie        40         6      1\n#&gt;   Chinstrap     14         7      3\n#&gt;   Gentoo         0         0     40\n\n# And our accuracy score\nmean(penguins_test$species == penguins_test$rpart_predicted_species)\n\n#&gt; [1] 0.7837838",
    "crumbs": [
      "Day 1",
      "kNN & Trees"
    ]
  },
  {
    "objectID": "01-knn-trees.html#your-turn-1",
    "href": "01-knn-trees.html#your-turn-1",
    "title": "kNN & Trees",
    "section": "2.4 Your turn!",
    "text": "2.4 Your turn!\nWe haven’t picked any hyperparameter settings for our tree yet, maybe we should try?\n\nWhat hyperparameters does rpart() offer? Do you recognize some from the lecture?\n\nYou can check via ?rpart.control\nWhen in doubt check minsplit, maxdepth and cp\n\nTry out trees with different parameters\n\nWould you prefer simple or complex trees?\nHow far can you improve the tree’s accuracy?\n\n\nSo, what seems to work better here?\nkNN or trees?\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nA “full” call to rpart with (most) relevant hyperparameters\n\nrpart_penguins &lt;- rpart(\n  formula = species ~ flipper_length_mm + body_mass_g,\n  data = penguins_train, # Train data\n  method = \"class\", # Grow a classification tree (don't change this)\n  cp = 0.03, # Complexity parameter for regularization (default = 0.01)\n  minsplit = 15, # Number of obs to keep in node to continue splitting, default = 20\n  minbucket = 2, # Number of obs to keep in terminal/leaf nodes, default is minsplit/3\n  maxdepth = 15 # Maximum tree depth, default (and upper limit for rpart!) = 30\n)\n\n# Evaluate\npenguins_test$rpart_predicted_species &lt;- rpart_predictions\n# Confusion matrix\ntable(penguins_test$species, penguins_test$rpart_predicted_species)\n\n#&gt;            \n#&gt;             Adelie Chinstrap Gentoo\n#&gt;   Adelie        40         6      1\n#&gt;   Chinstrap     14         7      3\n#&gt;   Gentoo         0         0     40\n\n# Accuracy\nmean(penguins_test$species == penguins_test$rpart_predicted_species)\n\n#&gt; [1] 0.7837838\n\n\nNot much else to show here, just play around with the parameters!",
    "crumbs": [
      "Day 1",
      "kNN & Trees"
    ]
  },
  {
    "objectID": "01-knn-trees.html#plotting-decision-boundaries-for-2-predictors",
    "href": "01-knn-trees.html#plotting-decision-boundaries-for-2-predictors",
    "title": "kNN & Trees",
    "section": "2.5 Plotting decision boundaries (for 2 predictors)",
    "text": "2.5 Plotting decision boundaries (for 2 predictors)\nThis is a rather cumbersome manual approach — there’s a nicer way we’ll see later, but we’ll do it the manual way at least once so you know how it works:\n\n# Decision tree to plot the boundaries of\nrpart_penguins &lt;- rpart(\n  formula = species ~ flipper_length_mm + body_mass_g,\n  data = penguins_train, # Train data\n  method = \"class\", # Grow a classification tree (don't change this)\n  cp = 0.005, # Default 0.01\n  minsplit = 20, # Default 20\n  minbucket = 3, # Default is minsplit/3\n  maxdepth = 30 # Default 30 (and upper limit!)\n)\n\n# Ranges of X and Y variable on plot\nflipper_range &lt;- range(penguins$flipper_length_mm)\nmass_range &lt;- range(penguins$body_mass_g)\n\n# A grid of values within these boundaries, 100 points per axis\npred_grid &lt;- expand.grid(\n  flipper_length_mm = seq(flipper_range[1], flipper_range[2], length.out = 100),\n  body_mass_g = seq(mass_range[1], mass_range[2], length.out = 100)\n)\n\n# Predict with tree for every single point\npred_grid$rpart_prediction &lt;- predict(\n  rpart_penguins,\n  newdata = pred_grid,\n  type = \"class\"\n)\n\n# Plot all predictions, colored by species\nggplot(pred_grid, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_tile(\n    aes(color = rpart_prediction, fill = rpart_prediction),\n    linewidth = 1,\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = penguins_test,\n    aes(fill = species),\n    shape = 21,\n    color = \"black\",\n    size = 2,\n    key_glyph = \"rect\"\n  ) +\n  labs(\n    title = \"Palmer Penguins: Decision Boundaries\",\n    subtitle = paste(\n      \"Species as predicted by decision tree\",\n      \"Point color is the true species\",\n      sep = \"\\n\"\n    ),\n    x = \"Flipper Length [mm]\",\n    y = \"Body Mass [g]\",\n    fill = \"Species\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(\n    legend.position = \"top\",\n    plot.title.position = \"plot\",\n    panel.grid = element_blank()\n  )",
    "crumbs": [
      "Day 1",
      "kNN & Trees"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "",
    "text": "This is the workshop component to the Machine Learning workshop in the Data Train 2025 series.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#day-1",
    "href": "index.html#day-1",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "1.1 Day 1",
    "text": "1.1 Day 1\n\nTheory / practice: 9:00 - 12:00\n\nk-Nearest-Neighbors\nGeneral concepts\nDecision Trees\n\nBreak: 12:00 - 13:00\nTheory / practice: 13:00 - 17:00\n\nRandom Forest\nModel evaluation\nBoosting",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#day-2",
    "href": "index.html#day-2",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "1.2 Day 2",
    "text": "1.2 Day 2\n\nTheory / practice: 9:00 - 12:00\n\nSupport Vector Machines (SVM)\nHyperparameter Tuning\nArtifical Neural Networks\n\nBreak: 12:00 - 13:00\nTheory / practice: 13:00 - 17:00\n\nSpecific endpoints\nVariable Importance\nDiscussion",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#manual-package-installation-instructions",
    "href": "index.html#manual-package-installation-instructions",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "3.1 Manual package installation instructions",
    "text": "3.1 Manual package installation instructions\n\n\nClick to expand instructions\n\nYou should only need to install all packages manually if you were not able to use renv to install them automatically. (Or if you’re trying to get this code to run in a different environment than this repository)\nIf you want to “disable” renv so you can manually install packages, open .Rprofile and comment out the following line:\nsource(\"renv/activate.R\")\nThe you can directly use {pak} for installation, which will try to automatically install system dependencies on Linux (see next note) if possible:\npackages &lt;- c(\n  # Data\n  \"palmerpenguins\", \"mlr3data\",\n  # Learner backends\n  \"ranger\", \"xgboost\", \"kknn\", \"rpart\", \"e1071\", \"randomForest\",\n  \"mlr3verse\", \"mlr3filters\", # installs \"mlr3\", \"mlr3learners\", \"mlr3viz\", \"mlr3tuning\" ...\n  \"precrec\", # ROC plots via mlr3, not auto-installed with mlr3viz\n  # Viz / interpretability\n  \"rpart.plot\", \"effectplots\",\n  # Plotting / infrastructure, goodies\n  \"rmarkdown\", \"ggplot2\", \"patchwork\", \"usethis\", \"dplyr\", \"purrr\", \"ragg\"\n)\n\n# Installing pak for faster package installation\ninstall.packages(\"pak\")\n\n# Install packages if not available already\npak::pak(packages)\n\n\n3.1.1 Linux Note\n\n\nClick to expand\n\nIf you’re working on a Linux distribution such as Ubuntu (or something Ubuntu-based), you may have to install some system packages with sudo apt-get install ... beforehand.\nFor Ubuntu it would look like this, which you can run in the terminal of your choice:\nsudo apt-get install -y git\nsudo apt-get install -y libcurl4-openssl-dev\nsudo apt-get install -y libfontconfig1-dev\nsudo apt-get install -y libfreetype6-dev\nsudo apt-get install -y libfribidi-dev\nsudo apt-get install -y libgit2-dev\nsudo apt-get install -y libglpk-dev\nsudo apt-get install -y libgmp3-dev\nsudo apt-get install -y libharfbuzz-dev\nsudo apt-get install -y libicu-dev\nsudo apt-get install -y libjpeg-dev\nsudo apt-get install -y libpng-dev\nsudo apt-get install -y libssl-dev\nsudo apt-get install -y libtiff-dev\nsudo apt-get install -y libxml2-dev\nsudo apt-get install -y make\nsudo apt-get install -y pandoc\nsudo apt-get install -y zlib1g-dev",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#code-examples",
    "href": "index.html#code-examples",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "4.1 Code examples",
    "text": "4.1 Code examples\nWe rely on the mlr3 framework and its free online book for the hands-on part of the workshop:\n\nBischl, B., Sonabend, R., Kotthoff, L., & Lang, M. Applied Machine Learning Using mlr3 in R. (CRC Press, 2024)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#free-lectures-online-with-slides-videos",
    "href": "index.html#free-lectures-online-with-slides-videos",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "4.2 Free Lectures (online with slides + videos)",
    "text": "4.2 Free Lectures (online with slides + videos)\nLecture materials take inspiration from these free and open-source lectures:\n\nIntroduction to Machine Learning (“I2ML”): https://slds-lmu.github.io/i2ml\nInterpretable Machine Learning: https://slds-lmu.github.io/iml",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#textbooks",
    "href": "index.html#textbooks",
    "title": "Data Train: Introduction to Machine Learning",
    "section": "4.3 Textbooks",
    "text": "4.3 Textbooks\n\nAn Introduction to Statistical Learning: with Applications in R. (Springer, 2013).\nHastie, T., Tibshirani, R. & Friedman, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition. (Springer, 2009).\nMurphy, K. P. Machine Learning: A Probabilistic Perspective. (MIT Press, 2012).\nBishop, C. M. Pattern Recognition and Machine Learning. Information Science and Statistics. (Springer, 2006).\nMolnar, M. Interpretable Machine Learning: A Guide for Making Black Box Models Explainable (2023)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "02-mlr3.html",
    "href": "02-mlr3.html",
    "title": "Introducing {mlr3}",
    "section": "",
    "text": "library(ggplot2) # For plotting\nlibrary(palmerpenguins) # For penguins\nlibrary(mlr3verse) # includes mlr3, mlr3learners, mlr3tuning, mlr3viz, ...\nGoals of this part:",
    "crumbs": [
      "Day 1",
      "Introducing `{mlr3}`"
    ]
  },
  {
    "objectID": "02-mlr3.html#creating-a-task",
    "href": "02-mlr3.html#creating-a-task",
    "title": "Introducing {mlr3}",
    "section": "1.1 Creating a task",
    "text": "1.1 Creating a task\nThe task encapsulates our data, including which features we’re using for learning and wich variable we use as the target for prediction. Tasks can be created in multiple ways and some standard example tasks are available in mlr3, but we’re taking the long way around.\nQuestions a task object answers:\n\nWhat is the task type, what kind of prediction are we doing?\n\nHere: Classification (instead of e.g. regression)\n\nWhat are we predicting on?\n\nThe dataset (“backend”), could be a data.frame, matrix, or a proper data base\n\nWhat variable are we trying to predict?\n\nThe target variable, here species\n\nWhich variables are we using for predictions?\n\nThe feature variables, which we can adjust\n\n\nSo let’s put our penguins into a task object for {mlr3} and inspect it:\n\n# Creating a classification task from our penguin data\npenguin_task &lt;- as_task_classif(\n  na.omit(palmerpenguins::penguins),\n  id = \"penguins\",\n  target = \"species\"\n)\n\npenguin_task\n\n#&gt; \n#&gt; ── &lt;TaskClassif&gt; (333x8) ───────────────────────────────────────────────────────\n#&gt; • Target: species\n#&gt; • Target classes: Adelie (44%), Gentoo (36%), Chinstrap (20%)\n#&gt; • Properties: multiclass\n#&gt; • Features (7):\n#&gt;   • int (3): body_mass_g, flipper_length_mm, year\n#&gt;   • dbl (2): bill_depth_mm, bill_length_mm\n#&gt;   • fct (2): island, sex\n\n\nWe can poke at it a little. Try typing penguin_task$ and hit the Tab key to trigger completions.\n\n# Contains our penguin dataset\npenguin_task$data()\n\n#&gt;        species bill_depth_mm bill_length_mm body_mass_g flipper_length_mm\n#&gt;         &lt;fctr&gt;         &lt;num&gt;          &lt;num&gt;       &lt;int&gt;             &lt;int&gt;\n#&gt;   1:    Adelie          18.7           39.1        3750               181\n#&gt;   2:    Adelie          17.4           39.5        3800               186\n#&gt;   3:    Adelie          18.0           40.3        3250               195\n#&gt;   4:    Adelie          19.3           36.7        3450               193\n#&gt;   5:    Adelie          20.6           39.3        3650               190\n#&gt;  ---                                                                     \n#&gt; 329: Chinstrap          19.8           55.8        4000               207\n#&gt; 330: Chinstrap          18.1           43.5        3400               202\n#&gt; 331: Chinstrap          18.2           49.6        3775               193\n#&gt; 332: Chinstrap          19.0           50.8        4100               210\n#&gt; 333: Chinstrap          18.7           50.2        3775               198\n#&gt;         island    sex  year\n#&gt;         &lt;fctr&gt; &lt;fctr&gt; &lt;int&gt;\n#&gt;   1: Torgersen   male  2007\n#&gt;   2: Torgersen female  2007\n#&gt;   3: Torgersen female  2007\n#&gt;   4: Torgersen female  2007\n#&gt;   5: Torgersen   male  2007\n#&gt;  ---                       \n#&gt; 329:     Dream   male  2009\n#&gt; 330:     Dream female  2009\n#&gt; 331:     Dream   male  2009\n#&gt; 332:     Dream   male  2009\n#&gt; 333:     Dream female  2009\n\n# We can ask it about e.g. our sample size and number of features\npenguin_task$nrow\n\n#&gt; [1] 333\n\npenguin_task$ncol\n\n#&gt; [1] 8\n\n# And what the classes are\npenguin_task$class_names\n\n#&gt; [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\n\n# What types of features do we have?\n# (relevant for learner support, some don't handle factors for example!)\npenguin_task$feature_types\n\n#&gt; Key: &lt;id&gt;\n#&gt;                   id    type\n#&gt;               &lt;char&gt;  &lt;char&gt;\n#&gt; 1:     bill_depth_mm numeric\n#&gt; 2:    bill_length_mm numeric\n#&gt; 3:       body_mass_g integer\n#&gt; 4: flipper_length_mm integer\n#&gt; 5:            island  factor\n#&gt; 6:               sex  factor\n#&gt; 7:              year integer\n\n\nWe can further inspect and modify the task after the fact if we choose:\n\n# Display feature and target variable assignment\npenguin_task$col_roles[c(\"feature\", \"target\")]\n\n#&gt; $feature\n#&gt; [1] \"bill_depth_mm\"     \"bill_length_mm\"    \"body_mass_g\"      \n#&gt; [4] \"flipper_length_mm\" \"island\"            \"sex\"              \n#&gt; [7] \"year\"             \n#&gt; \n#&gt; $target\n#&gt; [1] \"species\"\n\n# Maybe not all variables are useful for this task, let's remove some\npenguin_task$set_col_roles(\n  cols = c(\"island\", \"sex\", \"year\"),\n  remove_from = \"feature\"\n)\n\n# We can also explicitly assign the feature columns\npenguin_task$col_roles$feature &lt;- c(\"body_mass_g\", \"flipper_length_mm\")\n\n# Check what our current variables and roles are\npenguin_task$col_roles[c(\"feature\", \"target\")]\n\n#&gt; $feature\n#&gt; [1] \"body_mass_g\"       \"flipper_length_mm\"\n#&gt; \n#&gt; $target\n#&gt; [1] \"species\"\n\n\nSome variables may have missing values — if we had not excluded them in the beginning, you would find them here:\n\npenguin_task$missings()\n\n#&gt;           species       body_mass_g flipper_length_mm \n#&gt;                 0                 0                 0\n\n\n\n1.1.1 Train and test split\nWe’re mixing things up with a new train/test split, just for completeness in the example. For {mlr3}, we only need to save the indices / row IDs. There’s a handy partition() function that does the same think we did with sample() earlier, so let’s use that! We create another 2/3 train-test split. 2/3 is actually the default in partition() anyway.\n\nset.seed(26)\npenguin_split &lt;- partition(penguin_task, ratio = 2 / 3)\n\n# Contains vector of row_ids for train/test set\nstr(penguin_split)\n\n#&gt; List of 3\n#&gt;  $ train     : int [1:222] 2 3 4 8 9 10 13 17 19 20 ...\n#&gt;  $ test      : int [1:111] 1 5 6 7 11 12 14 15 16 18 ...\n#&gt;  $ validation: int(0)\n\n\nWe can now use penguin_split$train and penguin_split$test with every mlr3 function that has a row_ids argument.\n\n\n\n\n\n\nCaution\n\n\n\nThe row_ids of a task are not necessarily 1:N — there is no guarantee they start at 1, go up to N, or contain all integers in between. We can generally only expect them to be unique within a task!",
    "crumbs": [
      "Day 1",
      "Introducing `{mlr3}`"
    ]
  },
  {
    "objectID": "02-mlr3.html#picking-a-learner",
    "href": "02-mlr3.html#picking-a-learner",
    "title": "Introducing {mlr3}",
    "section": "1.2 Picking a Learner",
    "text": "1.2 Picking a Learner\nA learner encapsulates the fitting algorithm as well as any relevant hyperparameters, and {mlr3} supports a whole lot of learners to choose from. We’ll keep using {kknn} and {rpart} in the background for the classification task, but we’ll use {mlr3} on top of them for a consistent interface. So first, we have to find the learners we’re looking for.\nThere’s a lot more about learners in the mlr3 book, but for now we’re happy with the basics.\n\n# Lots of learners to choose from here:\nmlr_learners\n# Or as a large table:\nas.data.table(mlr_learners)\n\n# To show all classification learners (in *currently loaded* packages!)\nmlr_learners$keys(pattern = \"classif\")\n\n# There's also regression learner we don't need right now:\nmlr_learners$keys(pattern = \"regr\")\n\n# For the kknn OR rpart learners, we can use regex\nmlr_learners$keys(pattern = \"classif\\\\.(kknn|rpart)\")\n\nNow that we’ve identified our learners, we can get it quickly via the lrn() helper function:\n\nknn_learner &lt;- lrn(\"classif.kknn\")\n\nMost things in mlr3 have a $help() method which opens the R help page:\n\nknn_learner$help()\n\nWhat parameters does this learner have?\n\nknn_learner$param_set\n\n#&gt; &lt;ParamSet(6)&gt;\n#&gt;             id    class lower upper nlevels default  value\n#&gt;         &lt;char&gt;   &lt;char&gt; &lt;num&gt; &lt;num&gt;   &lt;num&gt;  &lt;list&gt; &lt;list&gt;\n#&gt; 1:           k ParamInt     1   Inf     Inf       7      7\n#&gt; 2:    distance ParamDbl     0   Inf     Inf       2 [NULL]\n#&gt; 3:      kernel ParamFct    NA    NA      10 optimal [NULL]\n#&gt; 4:       scale ParamLgl    NA    NA       2    TRUE [NULL]\n#&gt; 5:     ykernel ParamUty    NA    NA     Inf  [NULL] [NULL]\n#&gt; 6: store_model ParamLgl    NA    NA       2   FALSE [NULL]\n\n\nWe can get them by name as well:\n\nknn_learner$param_set$ids()\n\n#&gt; [1] \"k\"           \"distance\"    \"kernel\"      \"scale\"       \"ykernel\"    \n#&gt; [6] \"store_model\"\n\n\nSetting parameters leaves the others as default:\n\nknn_learner$configure(k = 5)\n\nknn_learner$param_set\n\n#&gt; &lt;ParamSet(6)&gt;\n#&gt;             id    class lower upper nlevels default  value\n#&gt;         &lt;char&gt;   &lt;char&gt; &lt;num&gt; &lt;num&gt;   &lt;num&gt;  &lt;list&gt; &lt;list&gt;\n#&gt; 1:           k ParamInt     1   Inf     Inf       7      5\n#&gt; 2:    distance ParamDbl     0   Inf     Inf       2 [NULL]\n#&gt; 3:      kernel ParamFct    NA    NA      10 optimal [NULL]\n#&gt; 4:       scale ParamLgl    NA    NA       2    TRUE [NULL]\n#&gt; 5:     ykernel ParamUty    NA    NA     Inf  [NULL] [NULL]\n#&gt; 6: store_model ParamLgl    NA    NA       2   FALSE [NULL]\n\n\nIdentical methods to set multiple or a single hyperparam, just in case you see them in other code somewhere:\n\nknn_learner$param_set$set_values(k = 9)\nknn_learner$param_set$values &lt;- list(k = 9)\nknn_learner$param_set$values$k &lt;- 9\n\nIn practice, we usually set the parameters directly when we construct the learner object:\n\nknn_learner &lt;- lrn(\"classif.kknn\", k = 7)\nknn_learner$param_set\n\n#&gt; &lt;ParamSet(6)&gt;\n#&gt;             id    class lower upper nlevels default  value\n#&gt;         &lt;char&gt;   &lt;char&gt; &lt;num&gt; &lt;num&gt;   &lt;num&gt;  &lt;list&gt; &lt;list&gt;\n#&gt; 1:           k ParamInt     1   Inf     Inf       7      7\n#&gt; 2:    distance ParamDbl     0   Inf     Inf       2 [NULL]\n#&gt; 3:      kernel ParamFct    NA    NA      10 optimal [NULL]\n#&gt; 4:       scale ParamLgl    NA    NA       2    TRUE [NULL]\n#&gt; 5:     ykernel ParamUty    NA    NA     Inf  [NULL] [NULL]\n#&gt; 6: store_model ParamLgl    NA    NA       2   FALSE [NULL]\n\n\nWe’ll save the {rpart} learner for later, but all the methods are the same because they are all Learner objects.",
    "crumbs": [
      "Day 1",
      "Introducing `{mlr3}`"
    ]
  },
  {
    "objectID": "02-mlr3.html#training-and-evaluating",
    "href": "02-mlr3.html#training-and-evaluating",
    "title": "Introducing {mlr3}",
    "section": "1.3 Training and evaluating",
    "text": "1.3 Training and evaluating\nWe can train the learner with default parameters once to see if it works as we expect it to.\n\n# Train learner on training data\nknn_learner$train(penguin_task, row_ids = penguin_split$train)\n\n# Look at stored model, which for knn is not very interesting\nknn_learner$model\n\n#&gt; $formula\n#&gt; species ~ .\n#&gt; NULL\n#&gt; \n#&gt; $data\n#&gt;        species body_mass_g flipper_length_mm\n#&gt;         &lt;fctr&gt;       &lt;int&gt;             &lt;int&gt;\n#&gt;   1:    Adelie        3800               186\n#&gt;   2:    Adelie        3250               195\n#&gt;   3:    Adelie        3450               193\n#&gt;   4:    Adelie        3200               182\n#&gt;   5:    Adelie        3800               191\n#&gt;  ---                                        \n#&gt; 218: Chinstrap        3650               189\n#&gt; 219: Chinstrap        3650               195\n#&gt; 220: Chinstrap        3400               202\n#&gt; 221: Chinstrap        3775               193\n#&gt; 222: Chinstrap        3775               198\n#&gt; \n#&gt; $pv\n#&gt; $pv$k\n#&gt; [1] 7\n#&gt; \n#&gt; \n#&gt; $kknn\n#&gt; NULL\n\n\nAnd we can make predictions on the test data:\n\nknn_prediction &lt;- knn_learner$predict(\n  penguin_task,\n  row_ids = penguin_split$test\n)\nknn_prediction\n\n#&gt; \n#&gt; ── &lt;PredictionClassif&gt; for 111 observations: ───────────────────────────────────\n#&gt;  row_ids     truth  response\n#&gt;        1    Adelie    Adelie\n#&gt;        5    Adelie    Adelie\n#&gt;        6    Adelie    Adelie\n#&gt;      ---       ---       ---\n#&gt;      326 Chinstrap Chinstrap\n#&gt;      329 Chinstrap Chinstrap\n#&gt;      332 Chinstrap    Gentoo\n\n\nOur predictions are looking quite reasonable, mostly:\n\n# Confusion matrix we got via table() previously\nknn_prediction$confusion\n\n#&gt;            truth\n#&gt; response    Adelie Chinstrap Gentoo\n#&gt;   Adelie        48         9      0\n#&gt;   Chinstrap      8         5      1\n#&gt;   Gentoo         3         1     36\n\n\nTo calculate the prediction accuracy, we don’t have to do any math in small steps. {mlr3} comes with lots of measures (like accuracy) we can use, they’re organized in the mlr_measures object (just like mlr_learners).\nWe’re using \"classif.acc\" here with the shorthand function msr(), and score our predictions with this measure, using the $score() method.\n\n# Available measures for classification tasks\nmlr_measures$keys(pattern = \"classif\")\n\n#&gt;  [1] \"classif.acc\"         \"classif.auc\"         \"classif.bacc\"       \n#&gt;  [4] \"classif.bbrier\"      \"classif.ce\"          \"classif.costs\"      \n#&gt;  [7] \"classif.dor\"         \"classif.fbeta\"       \"classif.fdr\"        \n#&gt; [10] \"classif.fn\"          \"classif.fnr\"         \"classif.fomr\"       \n#&gt; [13] \"classif.fp\"          \"classif.fpr\"         \"classif.logloss\"    \n#&gt; [16] \"classif.mauc_au1p\"   \"classif.mauc_au1u\"   \"classif.mauc_aunp\"  \n#&gt; [19] \"classif.mauc_aunu\"   \"classif.mauc_mu\"     \"classif.mbrier\"     \n#&gt; [22] \"classif.mcc\"         \"classif.npv\"         \"classif.ppv\"        \n#&gt; [25] \"classif.prauc\"       \"classif.precision\"   \"classif.recall\"     \n#&gt; [28] \"classif.sensitivity\" \"classif.specificity\" \"classif.tn\"         \n#&gt; [31] \"classif.tnr\"         \"classif.tp\"          \"classif.tpr\"        \n#&gt; [34] \"debug_classif\"\n\n# Scores according to the selected measure\nknn_prediction$score(msr(\"classif.acc\"))\n\n#&gt; classif.acc \n#&gt;   0.8018018\n\n# The inverse: Classification error (1 - accuracy)\nknn_prediction$score(msr(\"classif.ce\"))\n\n#&gt; classif.ce \n#&gt;  0.1981982\n\n\nAs a bonus feature, {mlr3} also makes it easy for us to plot the decision boundaries for a two-predictor case, so we don’t have to manually predict on a grid anymore.\n(You can ignore any warning messages from the plot here)\n\nplot_learner_prediction(\n  learner = knn_learner,\n  task = penguin_task\n)\n\n#&gt; INFO  [08:35:29.797] [mlr3] Applying learner 'classif.kknn' on task 'penguins' (iter 1/1)\n\n\n#&gt; Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.",
    "crumbs": [
      "Day 1",
      "Introducing `{mlr3}`"
    ]
  },
  {
    "objectID": "02-mlr3.html#your-turn",
    "href": "02-mlr3.html#your-turn",
    "title": "Introducing {mlr3}",
    "section": "1.4 Your turn!",
    "text": "1.4 Your turn!\nNow that we’ve done the kNN fitting with {mlr3}, you can easily do the same thing with the rpart-learner! All you have to do is switch the learner objects and give it a more fitting name.\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\n\n# Picking the learner\nrpart_learner &lt;- lrn(\"classif.rpart\")\n\n# What parameters does this learner have?\nrpart_learner$param_set$ids()\n\n#&gt;  [1] \"cp\"             \"keep_model\"     \"maxcompete\"     \"maxdepth\"      \n#&gt;  [5] \"maxsurrogate\"   \"minbucket\"      \"minsplit\"       \"surrogatestyle\"\n#&gt;  [9] \"usesurrogate\"   \"xval\"\n\n# Setting parameters (omit to use the defaults)\nrpart_learner$param_set$values$maxdepth &lt;- 20\n\n# Train\nrpart_learner$train(penguin_task, row_ids = penguin_split$train)\n\n# Predict\nrpart_prediction &lt;- rpart_learner$predict(penguin_task, row_ids = penguin_split$test)\n\nrpart_prediction$confusion\n\n#&gt;            truth\n#&gt; response    Adelie Chinstrap Gentoo\n#&gt;   Adelie        52         9      0\n#&gt;   Chinstrap      5         3      0\n#&gt;   Gentoo         2         3     37\n\n# Accuracy\nrpart_prediction$score(msr(\"classif.acc\"))\n\n#&gt; classif.acc \n#&gt;   0.8288288\n\nplot_learner_prediction(rpart_learner, penguin_task)\n\n#&gt; INFO  [08:35:30.411] [mlr3] Applying learner 'classif.rpart' on task 'penguins' (iter 1/1)\n\n\n#&gt; Warning: Raster pixels are placed at uneven horizontal intervals and will be shifted\n#&gt; ℹ Consider using `geom_tile()` instead.",
    "crumbs": [
      "Day 1",
      "Introducing `{mlr3}`"
    ]
  },
  {
    "objectID": "04-tuning.html",
    "href": "04-tuning.html",
    "title": "Tuning",
    "section": "",
    "text": "library(mlr3verse) # All the mlr3 things\nlibrary(ggplot2) # For plotting\nlgr::get_logger(\"mlr3\")$set_threshold(\"error\")\n\n# Spam Task setup\nspam_task &lt;- tsk(\"spam\")\nset.seed(26)\n\n# train/test split\nspam_split &lt;- partition(spam_task, ratio = 2 / 3)\nGoals of this part:",
    "crumbs": [
      "Day 2",
      "Tuning"
    ]
  },
  {
    "objectID": "04-tuning.html#your-turn",
    "href": "04-tuning.html#your-turn",
    "title": "Tuning",
    "section": "1.1 Your Turn!",
    "text": "1.1 Your Turn!\nAbove you have a boilerplate to tune your own learner. Start with either of the other three learners we’ve seen, pick one ore two hyperparameters to tune with a reasonable budget (note we have limited time and resources), tune on the training set and evaluate per AUC on the test set.\nSome pointers:\n\nConsult the Learner docs to see tuning-worthy parameters:\n\nlrn(\"classif.xgboost\")$help() links to the xgboost help\nlrn(\"classif.rpart\")$help() analogously for the decision tree\nYou can also see the documentation online, e.g. https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.xgboost.html\n\nParameter search spaces in ps() have different types, see the help at ?paradox::Domain\n\nUse p_int() for integers, p_dbl() for real-valued params etc.\n\nIf you don’t know which parameter to tune, try the following:\n\nclassif.xgboost:\n\nImportant: nrounds (integer) (&gt;= 1 (at least 50 or so))\nImportant: eta (double) (0 &lt; eta &lt; 1 (close to 0 probably))\nMaybe: max_depth (integer)\n\nclassif.rpart:\n\ncp (double)\nMaybe: maxdepth (integer) (&lt; 30)\n\nclassif.ranger:\n\nmtry (integer) -&gt; tune mtry.ratio (0 &lt; mtry.ratio &lt; 1)\nmax.depth (integer)\n\n\n\nNote: Instead of randomly picking parameters from the design space, we can also generate a grid of parameters and try those. We’ll not try that here for now, but you can read up on how to do that here: ?mlr_tuners_grid_search.\n-&gt; generate_design_grid(search_space, resolution = 5)\nAlso note that the cool thing about the auto_tuner() is that it behaves just like any other mlr3 learner, but it automatically tunes itself. You can plug it into resample() or benchmark_grid() just fine!\n\n# your code\n\n\n\n\n\n\n\nExample solution\n\n\n\n\n\nThe following example code uses the holdout resampling just to keep it fast — when you have the time, using cross-validation (\"cv\") will give you more reliable results.\nWe also use 6 threads for parallelization here, but you are free to adjust this according to your available hardware.\n\nfuture::plan(\"multisession\", workers = 6)\n\nThe tuning budget used here is just 50 evaluations, which as all you likely want to bump up a little if you have the time.\n\nrpart Tuningxgboost Tuningranger Tuning\n\n\n\n# Tuning setup\ntuned_rpart = auto_tuner(\n  learner = lrn(\"classif.rpart\", predict_type = \"prob\"),\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.auc\"),\n  search_space = ps(\n    cp = p_dbl(lower = 0.001, upper = 0.03),\n    maxdepth = p_int(lower = 1, upper = 30)\n  ),\n  terminator = trm(\"evals\", n_evals = 50),\n  tuner = tnr(\"random_search\")\n)\n\n# Tune!\ntuned_rpart$train(spam_task, row_ids = spam_split$train)\n\n# Evaluate!\ntuned_rpart$predict(spam_task, row_ids = spam_split$test)$score(msr(\n  \"classif.auc\"\n))\n\n#&gt; classif.auc \n#&gt;   0.9215502\n\n# Check parameter results\nautoplot(tuned_rpart$tuning_instance)\n\n\n\n\n\n\n\n\n\n\n\n# Tuning setup\ntuned_xgboost = auto_tuner(\n  learner = lrn(\"classif.xgboost\", predict_type = \"prob\"),\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.auc\"),\n  search_space = ps(\n    eta = p_dbl(lower = 0.001, upper = 1),\n    nrounds = p_int(lower = 1, upper = 500)\n  ),\n  terminator = trm(\"evals\", n_evals = 50),\n  tuner = tnr(\"random_search\")\n)\n\n# Tune!\ntuned_xgboost$train(spam_task, row_ids = spam_split$train)\n\nautoplot(tuned_xgboost$tuning_instance, cols_x = c(\"nrounds\", \"eta\"))\n\n\n\n\n\n\n\n# Evaluate!\ntuned_xgboost$predict(spam_task, row_ids = spam_split$test)$score(msr(\n  \"classif.auc\"\n))\n\n#&gt; classif.auc \n#&gt;   0.9876319\n\n\n\n\n\n# Tuning setup\ntuned_ranger = auto_tuner(\n  learner = lrn(\"classif.ranger\", predict_type = \"prob\"),\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.auc\"),\n  search_space = ps(\n    mtry.ratio = p_dbl(lower = 0, upper = 1),\n    max.depth = p_int(lower = 1, upper = 30)\n  ),\n  terminator = trm(\"evals\", n_evals = 50),\n  tuner = tnr(\"random_search\")\n)\n\n# Tune!\ntuned_ranger$train(spam_task, row_ids = spam_split$train)\n\n# Evaluate!\ntuned_ranger$predict(spam_task, row_ids = spam_split$test)$score(msr(\n  \"classif.auc\"\n))\n\n#&gt; classif.auc \n#&gt;   0.9834206\n\n# Check parameter results\nautoplot(tuned_ranger$tuning_instance)\n\n\n\n\n\n\n\n\n\n\n\n\n1.2 Benchmarking all the things (with tuning)\nAbove we tuned all the learners individually, but often we want to tune all of them at the same time to determine which performs best overall. For that, we use benchmark_grid() again (like in the second notebook), but now we just give it the AutoTuner-style learners instead of the “normal” learners.\nSince we have already set up the tuning-ready learners (tuned_&lt;method&gt; objects) above we just recycle them here, but we first reset all of them since we already tuned them and we want to start from scratch.\n\ntuned_knn$reset()\ntuned_rpart$reset()\ntuned_ranger$reset()\ntuned_xgboost$reset()\n\ntuning_learners &lt;- list(\n  tuned_knn,\n  tuned_rpart,\n  tuned_ranger,\n  tuned_xgboost\n)\n\ntuning_benchmark_design &lt;- benchmark_grid(\n  tasks = spam_task, # Still the same task. Optional: Use list() of multiple tasks for large benchmark study\n  learners = tuning_learners, # List of AutoTune-learners\n  resamplings = rsmp(\"holdout\") # Outer resampling strategy, holdout to keep it simpel\n)\n\n# Run the benchmark and save the results\nfuture::plan(\"multisession\", workers = 4)\nbmr &lt;- benchmark(tuning_benchmark_design)\n\n#&gt; Growing trees.. Progress: 28%. Estimated remaining time: 25 minutes, 3 seconds.\n\n# Who won?\nbmr$aggregate(msr(\"classif.auc\"))\n\n#&gt;       nr task_id            learner_id resampling_id iters classif.auc\n#&gt;    &lt;int&gt;  &lt;char&gt;                &lt;char&gt;        &lt;char&gt; &lt;int&gt;       &lt;num&gt;\n#&gt; 1:     1    spam    classif.kknn.tuned       holdout     1   0.9607047\n#&gt; 2:     2    spam   classif.rpart.tuned       holdout     1   0.9405357\n#&gt; 3:     3    spam  classif.ranger.tuned       holdout     1   0.9803224\n#&gt; 4:     4    spam classif.xgboost.tuned       holdout     1   0.9823780\n#&gt; Hidden columns: resample_result\n\n\nFor statistical tests on benchmark results, refer to the mlr3benchmark package (not included with mlr3verse).\n\n\n\n\n\n\n\n\n\n\nNot sure what to tune?\n\n\n\nWhich parameter to tune in which interval is usually an area of research, unless you have specific theory- or domain-driven constraints.\nThe mlr3tuningspaces packages aims to collect comprehensive tuning spaces for many learners, and when in doubt, they are usually a good place to start. Note that it’s most likely not necessary to extensively tune all parameters as much as possible — diminishing returns and such!",
    "crumbs": [
      "Day 2",
      "Tuning"
    ]
  },
  {
    "objectID": "04-tuning.html#benchmarking-all-the-things-with-tuning",
    "href": "04-tuning.html#benchmarking-all-the-things-with-tuning",
    "title": "Tuning",
    "section": "1.2 Benchmarking all the things (with tuning)",
    "text": "1.2 Benchmarking all the things (with tuning)\nAbove we tuned all the learners individually, but often we want to tune all of them at the same time to determine which performs best overall. For that, we use benchmark_grid() again (like in the second notebook), but now we just give it the AutoTuner-style learners instead of the “normal” learners.\nSince we have already set up the tuning-ready learners (tuned_&lt;method&gt; objects) above we just recycle them here, but we first reset all of them since we already tuned them and we want to start from scratch.\n\ntuned_knn$reset()\ntuned_rpart$reset()\ntuned_ranger$reset()\ntuned_xgboost$reset()\n\ntuning_learners &lt;- list(\n  tuned_knn,\n  tuned_rpart,\n  tuned_ranger,\n  tuned_xgboost\n)\n\ntuning_benchmark_design &lt;- benchmark_grid(\n  tasks = spam_task, # Still the same task. Optional: Use list() of multiple tasks for large benchmark study\n  learners = tuning_learners, # List of AutoTune-learners\n  resamplings = rsmp(\"holdout\") # Outer resampling strategy, holdout to keep it simpel\n)\n\n# Run the benchmark and save the results\nfuture::plan(\"multisession\", workers = 4)\nbmr &lt;- benchmark(tuning_benchmark_design)\n\n#&gt; Growing trees.. Progress: 28%. Estimated remaining time: 25 minutes, 3 seconds.\n\n# Who won?\nbmr$aggregate(msr(\"classif.auc\"))\n\n#&gt;       nr task_id            learner_id resampling_id iters classif.auc\n#&gt;    &lt;int&gt;  &lt;char&gt;                &lt;char&gt;        &lt;char&gt; &lt;int&gt;       &lt;num&gt;\n#&gt; 1:     1    spam    classif.kknn.tuned       holdout     1   0.9607047\n#&gt; 2:     2    spam   classif.rpart.tuned       holdout     1   0.9405357\n#&gt; 3:     3    spam  classif.ranger.tuned       holdout     1   0.9803224\n#&gt; 4:     4    spam classif.xgboost.tuned       holdout     1   0.9823780\n#&gt; Hidden columns: resample_result\n\n\nFor statistical tests on benchmark results, refer to the mlr3benchmark package (not included with mlr3verse).",
    "crumbs": [
      "Day 2",
      "Tuning"
    ]
  },
  {
    "objectID": "06-feature-selection.html",
    "href": "06-feature-selection.html",
    "title": "Feature Selection",
    "section": "",
    "text": "library(mlr3verse) # All the mlr3 things\n\n# Spam Task setup\nspam_task &lt;- tsk(\"spam\")\nGoals of this part:",
    "crumbs": [
      "Day 2",
      "Feature Selection"
    ]
  },
  {
    "objectID": "06-feature-selection.html#your-turn-for-some-other-time",
    "href": "06-feature-selection.html#your-turn-for-some-other-time",
    "title": "Feature Selection",
    "section": "1.1 Your turn! (For some other time)",
    "text": "1.1 Your turn! (For some other time)\n\nTry out the bike sharing task (tsk(\"bike_sharing\"))\nRead the docs to see the meaning of each feature\nTry out different feature selection approaches!\n\nNote that this task has a few more observations, so it’s going to take a bit longer.\nWe don’t want to spend the in-person session staring overheating laptops, so you can try this out in your own time!",
    "crumbs": [
      "Day 2",
      "Feature Selection"
    ]
  }
]